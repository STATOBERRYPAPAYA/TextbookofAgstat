[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "TEXTBOOK OF AGRICULTURAL STATISTICS",
    "section": "",
    "text": "Welcome\nWelcome to the Textbook of Agricultural Statistics – a comprehensive resource thoughtfully crafted by the Department of Agricultural Statistics at the College of Agriculture, Vellayani, Kerala Agricultural University. This book was created to meet the need for a clear, accessible, and practical guide to statistics tailored for agricultural research.\nStatistics is an essential tool in agriculture, enabling researchers and practitioners to uncover patterns, validate results, and make data-driven decisions. However, the subject is often perceived as complex and challenging to master. This textbook is designed to change that perception, offering straightforward explanations and practical guidance to make statistical concepts approachable and applicable.\nAs John Tukey once said, “The greatest value of a picture is when it forces us to notice what we never expected to see.” We have embraced this philosophy by incorporating clear examples, practical applications, and data visualizations to illustrate concepts and deepen understanding.\nWhile this book is primarily written with undergraduate students in mind, its simplicity and focus on real-world applications make it a valuable resource for a wide audience, including postgraduate students, researchers, and anyone seeking to build a strong foundation in statistics and experimental design.\nYou will find clear explanations, practical examples, and step-by-step instructions throughout the chapters, all tailored to the unique needs of agricultural studies. Our goal is to ensure that learners at all levels can confidently apply statistical methods to their work and research.\nWhether you are new to statistics or looking to revisit the basics with a fresh perspective, we hope this book serves as a supportive companion in your journey to understanding and applying statistical tools effectively in agriculture.\n\nAcknowledgements\nThis book is the result of collaborative efforts among dedicated teachers and statisticians, but the majority of the reviewing, editing, and refinement has been inspired and shaped by the students.\nFor two years, this book was made available online on the MeLON (Module for eLearning and Online Notes) platform of the College of Agriculture, Vellayani. During this time, students provided valuable feedback, pointed out areas for improvement, and offered insights that greatly enhanced the quality and clarity of the content. We are sincerely grateful to all the students whose suggestions and input played a key role in the development of this textbook.\nWe would also like to thank the College of Agriculture, Vellayani, for fostering an environment that encourages learning, growth, and the sharing of ideas.\n\n\nNote from the Publisher\nThis textbook is published by PAPAYA, the publication division of Statoberry LLP, which is committed to providing high-quality educational resources for agricultural research. The online version of this book is available for free, in line with our dedication to open access and knowledge sharing. Visit us at PAPAYA.\n\n\nCopyright Information\n© 2024 Statoberry LLP. All rights reserved.\nOnline version of this book is licensed under a\n\nCreative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.\nUnder this license:\n- Attribution: You must give appropriate credit, provide a link to the license, and indicate if changes were made.\n- Non Commercial: You may not use the material for commercial purposes.\n- No Derivatives: If you remix, transform, or build upon the material, you may not distribute the modified material.\nFor commercial use or distribution of print copies, prior written permission from Statoberry LLP is required.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface",
    "section": "",
    "text": "For a long time, I have dreamed of writing a book that truly serves the needs of undergraduate students in agriculture—a book that demystifies statistics and makes it accessible and practical for their studies and research. Statistics, while being an essential tool in agricultural sciences, is often presented in ways that make it seem more complicated than it actually is. Textbooks in this field tend to delve into intricate details that go far beyond what most agricultural students require, leaving them overwhelmed and disconnected from the subject’s practical relevance.\nThis book is my humble attempt to change that. It has been written with undergraduate students in mind, focusing on the basics of statistics and their direct applications in agricultural research. Each chapter is designed to simplify complex concepts, making them clear, relatable, and easy to understand. While the primary audience is undergraduate students, this book can also serve as a helpful resource for anyone looking to brush up on the fundamentals of statistics.\nThe journey of writing this book has been greatly enriched by the feedback and insights of the students at the College of Agriculture, Vellayani. For two years, an earlier version of this book was made available on MeLON (Module for eLearning and Online Notes), our college’s online platform. The students, with their thoughtful suggestions and sharp observations, have helped refine the content and shape it into what it is today. Their enthusiasm and curiosity have been a constant source of inspiration throughout this process.\nI would also like to express my heartfelt gratitude to my co-authors, Dr. Manju Mary Paul, Dr. Adarsh V. S., and Mohammed Hisham M., whose expertise, commitment, and contributions have been invaluable in bringing this book to life. Their collaboration and dedication have greatly enhanced the quality and depth of this work.\nA special thanks to Jithin Chandran, Gaatha Prasad, Anjana Biwas T., and Varsha H. for their valuable suggestions and minor corrections. They were postgraduate students in Agricultural Statistics at the time of writing this book, and their support has significantly increased the quality of this work.\nI hope this textbook becomes a guiding light for students and researchers alike, helping them build a solid foundation in statistics while inspiring confidence in their ability to use these tools effectively. If this book makes statistics less intimidating and more approachable for even one reader, I will consider my efforts worthwhile.\nWith deep gratitude to my students, colleagues, and everyone who supported this work, I present this book as a tool to empower the next generation of agricultural scientists and researchers.\nDr. Pratheesh P. Gopinath\nHead\nDepartment of Agricultural Statistics\nCollege of Agriculture, Vellayani\n2 December 2024",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Basics of statistics",
    "section": "",
    "text": "1.1 The word “statistics”\nStatistics is the science of understanding, analyzing, and interpreting data. It plays a crucial role in making informed decisions across various fields, from agriculture to medicine, economics to environmental studies. This chapter serves as an entry point into the fascinating world of statistics, introducing you to its basic concepts and practical applications.\nWe begin by exploring the origins and definitions of statistics, emphasizing its relationship with mathematics and its distinct role in solving real-world problems. From there, we focus on the importance of data—the raw material of statistics—examining its types and how it is collected, organized, and analyzed.\nThe chapter also covers essential concepts such as population and sample, variables and constants, and the different types of variables. These concepts form the building blocks for understanding how statistical studies are designed and conducted.\nFinally, we introduce frequency distributions—an indispensable tool for summarizing and interpreting data. Topics such as construction of frequency distributions, grouped and cumulative frequency distributions, and relative frequency will help you make sense of data and uncover underlying patterns.\nBy the end of this chapter, you will have a comprehensive understanding of the core principles of statistics, setting the stage for deeper exploration and advanced applications in later chapters. The concepts presented here are largely based on the works of (Goon and Dasgupta 1983) and (Gupta and Kapoor 1997)\nThe term statistics originates from the Neo-Latin word statisticum collegium, meaning “council of state,” and the Italian word statista, meaning “statesman” or “politician.” The German term Statistik emerged in the early 18th century and initially referred to the “collection and classification of data,” particularly data used by governments and administrative bodies. This usage was introduced by the German scholar Gottfried Achenwall in 1749, who is often credited as the founder of modern statistics.\nIn 1791, Sir John Sinclair introduced the term Statistik into English through his publication of the “Statistical Account of Scotland”(Ball 2004), a comprehensive 21-volume work. This marked the beginning of the use of the term statistics in English to describe the systematic collection and analysis of data. Later, in 1845, Francis G.P. Neison an actuary1 to the Medical Invalid and General Life Office published Contributions to Vital Statistics, the first book to include the word “statistics” in its title, focusing on actuarial and demographic data. These developments laid the foundation for statistics as a discipline, evolving from statecraft to a broader scientific approach to data analysis and interpretation.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#the-word-statistics",
    "href": "intro.html#the-word-statistics",
    "title": "1  Basics of statistics",
    "section": "",
    "text": "Figure 1.1: Statistical Account of Scotland by Sir John Sinclair (1791)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#statistics-and-mathematics",
    "href": "intro.html#statistics-and-mathematics",
    "title": "1  Basics of statistics",
    "section": "1.2 Statistics and mathematics",
    "text": "1.2 Statistics and mathematics\nMathematics and statistics, while closely related, serve distinct purposes and operate on fundamentally different principles. Mathematics can be thought of as a well-organized library, where everything follows strict rules and logical paths. Once a theorem is proven in mathematics, it remains universally true, leaving little room for ambiguity or change. It is a deductive science, relying on precise axioms and logical reasoning to arrive at exact and unchanging results.\nStatistics, however, operates in a different realm. It deals with real-world data, which is often messy, unpredictable, and influenced by numerous uncontrolled factors. Statistics is more like an open field, where methods and approaches must adapt to the variability of data. Unlike the certainty of mathematics, statistics uses inductive reasoning to analyze data, account for randomness, and make decisions or predictions under uncertainty. This flexibility is essential because real-world phenomena, especially in fields like biology, are rarely as neat and predictable as mathematical constructs.\nIn biological sciences, we study complex systems such as plants, animals, and ecosystems, where exact outcomes are rarely achievable. These systems are influenced by a multitude of factors, many of which cannot be precisely measured or controlled. This is where the concept of the error term becomes important. The error term represents the difference between observed and predicted values in a statistical model, accounting for the inherent variability and uncertainty in biological phenomena.\nStatisticians embrace this uncertainty, developing mathematical models that approximate reality as closely as possible. Unlike mathematicians, whose focus is on achieving perfect precision, statisticians aim to draw meaningful insights from imperfect and variable data. In the study of biological systems, the goal is not to eliminate uncertainty but to understand patterns, relationships, and trends within the data.\nThus, while mathematics seeks absolute certainty, statistics accepts variability and uncertainty as fundamental characteristics of the real world. By acknowledging and incorporating these uncertainties, statisticians provide valuable tools to study and explain complex biological phenomena, making statistics an indispensable discipline for understanding the complexities of nature.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#definition-of-statistics",
    "href": "intro.html#definition-of-statistics",
    "title": "1  Basics of statistics",
    "section": "1.3 Definition of statistics",
    "text": "1.3 Definition of statistics\nStatistics is the science which deals with the\n\nCollection of data\nOrganization of data or classification of data\nPresentation of data\nAnalysis of data\nInterpretation of data\n\n\n\n\n\n\n\nJust for Fun\n\n\n\nLet’s give a definition to statistics using the words themselves:\nStrengthening Technological Advancement Through Implementing Systematic Techniques in Contemporary Sciences\n\n\nTwo main branches of statistics are:\nDescriptive statistics, which deals with summarizing data from a sample using indexes such as the mean or standard deviation etc.\nInferential statistics, use a random sample of data taken from a population to describe and make inferences about the population parameters.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#data",
    "href": "intro.html#data",
    "title": "1  Basics of statistics",
    "section": "1.4 Data",
    "text": "1.4 Data\nData can be defined as individual pieces of factual information that are recorded and used to draw meaningful insights through the science of statistics. Think of data as the building blocks that form the foundation for understanding the world around us. It’s the raw material from which we extract patterns, trends, and conclusions that help us make better decisions.\nIn today’s fast-paced world, data is more important than ever. From predicting weather patterns to optimizing business strategies, data is at the heart of nearly every advancement. Without data, we’re left with guesswork—making it impossible to understand complex systems or make informed decisions.\nHere are some examples of data in action:\n\nNumber of farmers in a village: Understanding this helps policymakers make decisions about agricultural development and rural economics.\nRainfall over a period of time: This data is crucial for predicting crop yields, planning irrigation, and managing water resources.\nArea under paddy crop in a state: This informs agricultural policies, resource allocation, and even global food supply chains.\n\nAs you can see, data isn’t just a collection of numbers; it’s the key to solving real-world problems and shaping the future. In the hands of skilled statisticians, data has the power to unlock insights that can improve lives, drive innovation, and guide decisions at every level.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#scope-and-limits",
    "href": "intro.html#scope-and-limits",
    "title": "1  Basics of statistics",
    "section": "1.5 Scope and limits",
    "text": "1.5 Scope and limits\nFunctions of statistics: Statistics plays a crucial role in simplifying complex data, transforming it into clear and meaningful information. It supports decision-making by presenting facts in an organized manner, aids in the formulation of effective policies, facilitates comparisons, and assists in making forecasts. By applying appropriate statistical methods, researchers can draw valid conclusions from experiments.\nApplications of statistics: Statistics has become an integral part of almost every field of human activity. It is indispensable in areas such as administration, business, economics, research, banking, insurance, and more. Its ability to quantify and analyze data makes it an essential tool across industries.\nCommon limitations of statistics: Statistical methods are applicable only when there is variability in the data being studied. Statistics focuses on the analysis of groups or aggregates, rather than individual data points. The results derived from statistical analysis are often approximate and subject to uncertainty. Statistics is sometimes misapplied or misinterpreted, leading to erroneous conclusions.\nAs statisticians, we believe that the power of statistics knows no bounds. It’s a tool that, when applied correctly, can unlock insights from any dataset. While the limitations listed above are commonly found in textbooks and curricula across SAUs (State Agricultural Universities), I believe these are more about guiding students on the appropriate use of statistics rather than presenting true constraints. With the right methodology and approach, statistics can be applied in any situation to derive valuable insights and support sound decision-making.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#population-and-sample",
    "href": "intro.html#population-and-sample",
    "title": "1  Basics of statistics",
    "section": "1.6 Population and sample",
    "text": "1.6 Population and sample\nConsider the following example. Suppose we wish to study the height of all students in a college. It will take us a long time to measure the height of all students of the college, so we may select 20 of the students and measure their height (in cm). Suppose we obtain the measurements like this :\n149, 156, 148, 161, 159, 143, 158, 152, 164, 171, 157, 152, 163,\n158, 151, 147, 157, 146, 153, 159.\nIn this study, we are interested in the height of all students in the college. The set of height of all students in the college is called the population of this study. The set of 20 height, H = {149, 156,148, …, 153, 159}, is a sample from this population.\nPopulation\nIn statistics, a population refers to the entire collection of elements, individuals, or objects that possess a particular characteristic and are the subject of a statistical study. It encompasses all possible observations or measurements that could be included in the analysis. For example, a population could be all the students in a university, all the trees in a forest, or all the farms in a region. The population provides the complete set of data from which conclusions can be drawn.\nSample\nA sample is a subset of a population selected for the purpose of conducting a statistical analysis. It represents a smaller group drawn from the population, ideally chosen to reflect its characteristics. Samples are used to estimate population parameters when it is impractical or impossible to collect data from the entire population. The key to a good sample is that it should be representative of the population to allow valid inferences to be made.\nPopulation parameter\nA population parameter is a numerical characteristic or value that describes an aspect of an entire population. It is a fixed (constant), often unknown value that represents the true measurement of a specific attribute for every member of the population. Common population parameters include the population mean, population variance, and population proportion. Since it is usually impractical or impossible to measure the entire population, parameters are often estimated using sample data.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#variables-and-constants",
    "href": "intro.html#variables-and-constants",
    "title": "1  Basics of statistics",
    "section": "1.7 Variables and constants",
    "text": "1.7 Variables and constants\nVariables\nA variable is a characteristic or attribute that can take different values for different individuals, at different times, or in different locations. In other words, variables are subject to change. Examples of variables include:\n\nThe number of fruits on a branch, the number of plots in a field, or the number of schools in a country.\nPlant height, crop yield, panicle length, or temperature.\n\nVariables can be classified into two broad categories: quantitative variables, which are measured on a numerical scale (such as height or yield), and qualitative (or categorical) variables, which describe categories or characteristics (such as plant species or color).\nConstants\nA constant refers to a value that does not change under any circumstances. Unlike variables, constants retain the same value throughout the study. Examples of constants include:\n\nMathematical values such as pi (\\(\\pi\\)), which is the ratio of the circumference of a circle to its diameter (\\(\\pi\\) = 3.14159…), and e, the base of the natural logarithms (e = 2.71828).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#types-of-variables",
    "href": "intro.html#types-of-variables",
    "title": "1  Basics of statistics",
    "section": "1.8 Types of variables",
    "text": "1.8 Types of variables\nQuantitative variables\nA quantitative variable is one that can be expressed in numerical terms and takes values that are measurable. Examples of quantitative variables include the number of fruits on a branch, the number of plots in a field, the number of schools in a country, plant height, crop yield, panicle length, and temperature. Quantitative variables can be further classified into two categories: discrete and continuous.\nDiscrete variables\nDiscrete variables are variables that can only take a finite or countable number of distinct values. They are often whole numbers and can be counted. For instance, the number of fruits on a branch, the number of plots in a field, or the number of schools in a country are all discrete variables.\nSince discrete variables represent countable quantities, they can only take specific, separate values, such as 0, 1, 2, etc. For example, the number of daily hospital admissions is a discrete variable because it can only take whole number values like 0, 1, or 2, but not fractional values like 1.8 or 3.96.\nContinuous variables\nContinuous variables, on the other hand, are variables that can take any value within a given range or interval and can be measured. These variables do not have distinct gaps or interruptions in their possible values. For example, plant height, yield, temperature, and panicle length are continuous variables because they can be measured to a high degree of precision, such as 5.5 cm, 5.8 cm, or any value within a relevant range. Continuous variables can assume an infinite number of possible values within a given range, making them different from discrete variables.\nCategorical variables\nA categorical variable is a type of variable where the data is divided into distinct categories that do not have a numerical value. For example, marital status (single, married, widowed), employment status (employed, unemployed), or religious affiliation (Protestant, Catholic, Jewish, Muslim, others) are examples of categorical variables. These variables are often referred to as qualitative variables, as they describe qualities or characteristics rather than measurable quantities.\nUnlike quantitative variables, categorical variables cannot be measured or counted in the traditional sense. Instead, they classify data into specific groups or categories.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#measurement-scales",
    "href": "intro.html#measurement-scales",
    "title": "1  Basics of statistics",
    "section": "1.9 Measurement scales",
    "text": "1.9 Measurement scales\nVariables can be classified into four distinct levels of measurement scales each representing a different way of organizing and interpreting data. These four levels are nominal, ordinal, interval, and ratio.\nNominal scale\nThe nominal scale is the most basic level of measurement and applies to categorical (qualitative) variables. Data measured on the nominal scale consist of categories that are distinct but have no inherent order or ranking. The categories are simply used for labeling or naming objects or groups. For example, gender (male, female), blood group (A, B, AB, O), and marital status (single, married, divorced) are all nominal variables. In the nominal scale, arithmetic operations, such as addition or subtraction, cannot be performed on the data.\nOrdinal scale\nThe ordinal scale also applies to qualitative data, but with an important distinction: the data on the ordinal scale are ordered. This means that the categories have a specific rank or order, but the differences between the categories are not necessarily uniform or meaningful. For example, the grades given in a class (excellent, good, fair, poor) are ordinal, where “excellent” is ranked higher than “good,” and “good” is ranked higher than “fair,” and so on. However, the difference between “excellent” and “good” is not numerically defined, making the exact magnitude of the difference unclear. Ordinal data allows us to say that one value is greater or lesser than another, but it does not allow for the measurement of exact differences.\nInterval scale\nThe interval scale is used for quantitative (numerical) data, and it provides more information than the nominal or ordinal scales. On the interval scale, the data points are ordered, and the differences between them are meaningful and measurable. However, the interval scale does not have a true zero point. This means that while we can measure the difference between values, we cannot make statements about ratios between them. An example of an interval scale is temperature measured in Celsius or Fahrenheit. For instance, if the temperature in two cities is 20°C and 30°C, we can say that the temperature in the second city is 10°C higher. However, we cannot say that the second city is “twice as hot” as the first city, because the zero point (0°C) does not represent the absence of temperature.\nRatio scale\nThe ratio scale is the highest level of measurement and applies to quantitative data. It shares the properties of the interval scale—ordered data with measurable differences between values—but it also has a meaningful zero point. This true zero point represents the total absence of the quantity being measured. With the ratio scale, not only can we measure differences between values, but we can also compute meaningful ratios. For example, weight is measured on the ratio scale. A weight of 60 kg is twice as much as a weight of 30 kg, and a weight of 0 kg indicates the complete absence of weight. Similarly, temperature measured on the Kelvin scale is an example of a ratio scale, where 0 Kelvin represents absolute zero, the complete absence of heat.\nIn summary, the key distinctions between these measurement scales are:\n\nNominal: Categories without any order.\nOrdinal: Ordered categories without consistent differences.\nInterval: Ordered data with meaningful differences, but no true zero.\nRatio: Ordered data with meaningful differences and a true zero point, allowing for meaningful ratios.\n\n\n\n\n\n\n\nFigure 1.2: Classification of variables",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#collection-of-data",
    "href": "intro.html#collection-of-data",
    "title": "1  Basics of statistics",
    "section": "1.10 Collection of data",
    "text": "1.10 Collection of data\nThe process of collecting data is the foundational step in any statistical investigation or research study. Data can be gathered for an entire population or for a sample drawn from it. Typically, data collection is performed on a sample basis, especially when studying large populations. Collecting data is a challenging task, requiring skill and precision. The person responsible for gathering the data, known as the enumerator or investigator, must be well-trained to ensure the accuracy and reliability of the data collected. The individuals or groups providing the information are referred to as the respondents.\n\n1.10.1 Types of data\nData collection can be categorized into two main types based on the source from which the data is derived:\n\nPrimary Data\nSecondary Data\n\nPrimary data\nPrimary data refer to first-hand, original data that are collected directly by the researcher or an organization for a specific purpose. These data have not been processed or analyzed previously and are considered the most authentic form of data. Primary data are typically gathered through surveys, interviews, experiments, or observations, and they represent a direct reflection of the phenomena being studied.\nExample: Population census data collected by the government are considered primary data. These are collected directly from individuals by government authorities for the purpose of census enumeration and demographic analysis.\nSecondary data\nSecondary data refer to data that have already been collected, processed, and published by other organizations or researchers for a different purpose. These data may have undergone some degree of analysis or treatment before being made available for new studies. Secondary data are often more convenient to use, as they are readily accessible, but they may not always perfectly suit the specific needs of the researcher.\nExample: An economic survey of a country, such as reports from the Bureau of Statistics or other governmental agencies, is an example of secondary data. These data were originally collected for purposes such as policy analysis or economic planning, and now can be used for additional research.\nThe distinction between primary and secondary data lies primarily in their origin and the process of collection. Primary data are first-hand, original data collected directly from a single source by the researcher for a specific purpose. These data are considered pure as they have not undergone any prior statistical treatment. In contrast, secondary data are obtained from existing sources or agencies and have been previously collected and processed for different purposes. They are not considered pure as they have undergone some form of statistical treatment. While primary data are original and collected for the first time, secondary data are pre-existing and gathered from other sources. Both types of data have their respective advantages and limitations, and the choice between them depends on the research objectives, availability of resources, and the nature of the study.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#collecting-primary-data",
    "href": "intro.html#collecting-primary-data",
    "title": "1  Basics of statistics",
    "section": "1.11 Collecting primary data",
    "text": "1.11 Collecting primary data\nPrimary data can be collected using various methods, depending on the research requirements and resources available:\nPersonal investigation\nIn this method, the researcher directly conducts the survey and collects the data themselves. This approach often results in highly accurate and reliable data. It is best suited for small-scale research projects where direct involvement of the researcher is feasible.\nThrough investigation\nIn this method, trained investigators are employed to collect data. These investigators engage with individuals, asking questions and filling out questionnaires based on the responses. This method is widely used by organizations for larger data collection efforts.\nCollection through questionnaire\nResearchers distribute questionnaires to local representatives or agents who collect data based on their own experience and observations. While this method is relatively quick, it typically provides only a rough estimate of the information.\nThrough the phone\nData is gathered by contacting individuals via telephone/mobile phone. This method is fast and allows for accurate information to be collected efficiently, making it suitable for studies that require a broad reach but still need reliable data.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#collecting-secondary-data",
    "href": "intro.html#collecting-secondary-data",
    "title": "1  Basics of statistics",
    "section": "1.12 Collecting secondary data",
    "text": "1.12 Collecting secondary data\nSecondary data are collected through various established channels:\nOfficial\nOfficial sources include publications from government bodies such as the Statistical Division, Ministry of Finance, Federal Bureaus of Statistics, and various ministries (e.g., Agriculture, Food, Industry, Labor). These sources provide comprehensive and authoritative data.\nSemi-Official\nSemi-official sources include publications from institutions like the State Bank, Railway Board, Central Cotton Committee, and Boards of Economic Enquiry. It also encompasses reports from trade associations, chambers of commerce, technical journals, trade publications, and research organizations such as universities and other academic institutions. These sources provide valuable data, though they may not be as universally authoritative as official sources.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#frequency-distribution",
    "href": "intro.html#frequency-distribution",
    "title": "1  Basics of statistics",
    "section": "1.13 Frequency distribution",
    "text": "1.13 Frequency distribution\nThe data presented below shows the number of fruits per branch in a mango tree selected from a particular plot. The data, presented in this form in which it was collected, is called raw data.\n0, 1, 0, 5, 2, 3, 2, 3, 1, 5,\n5, 2, 3, 4, 4, 5, 4, 0, 5, 4,\n2, 4, 4, 4, 1\nIt can be seen that, the minimum and the maximum numbers of fruits per branch are 0 and 5, respectively. Apart from these numbers, it is impossible, without further careful study, to extract any exact information from the data. But by breaking down the data into the form below\n\n\n\nFrequency distribution table\n\n\nNow certain features of the data become apparent. For instance, it can easily be seen that, most of the branches selected have four fruits because number of branches having 4 fruits is 7. This information cannot easily be obtained from the raw data. The above table is called a frequency table or a frequency distribution. It is so called because it gives the frequency or number of times each observation occurs. Thus, by finding the frequency of each observation, a more intelligible picture is obtained.\n\n1.13.1 Construction\nIn this section, we will discuss the process of constructing a frequency distribution. Follow the steps below. This method helps to clearly visualize the frequency of each observation, ensuring that the total frequency adds up to the total number of observations.\n\nList all values of the variable in ascending order of magnitude.\nForm a tally column, that is, for each value in the data, record a stroke in the tally column next to that value. In the tally, each fifth stroke is made across the first four. This makes it easy to count the entries and enter the frequency of each observation.\nCheck that the frequencies sum to the total number of observations",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#grouped-frequency-distribution",
    "href": "intro.html#grouped-frequency-distribution",
    "title": "1  Basics of statistics",
    "section": "1.14 Grouped frequency distribution",
    "text": "1.14 Grouped frequency distribution\nData below gives the plant height of 20 paddy varieties, measured to the nearest centimeters.\n109, 107, 129, 122, 118, 110, 124, 146, 138, 121,\n115, 132, 131, 139, 142, 134, 143, 144, 127, 116\nIt can be seen that the minimum and the maximum plant height are 107 cm and 144 cm, respectively. A frequency distribution giving every plant height between 107 cm and 144 cm would be very long and would not be very informative. The problem is to overcome by grouping the data into classes.\nIf we choose the classes\n100 – 109\n110 – 119\n120 – 129\n130 – 139\n140 – 149\nwe obtain the frequency distribution given below:\n\n\n\nGrouped Frequency distribution table\n\n\nAbove table gives the frequency of each group or class; it is therefore called a grouped frequency table or a grouped frequency distribution. Using this grouped frequency distribution, it is easier to obtain information about the data than using the raw data. For instance, it can be seen that 14 of the 20 paddy varieties have plant height between 110 cm and 139 cm (both inclusive). This information cannot easily be obtained from the raw data.\nIt should be noted that, even though above table is concise, some information is lost. For example, the grouped frequency distribution does not give us the exact plant height of the paddy varieties. Thus the individual plant height of the paddy varieties are lost in our effort to obtain an overall picture.\n\n1.14.1 Terminologies\nClass limits\nThe intervals into which the observations are put are called class intervals. The end points of the class intervals are called class limits. For example, the class interval 100 – 109, has lower class limit 100 and upper class limit 109.\nContinuous classes\nContinuous classes are intervals where the class limits represent a continuous range of values, with no gaps between the intervals.\nExample: If the class intervals are 10 − 20, 20−30, 30−40, and so on, there are no gaps between them, and all values within these ranges are included seamlessly.\nDiscontinuous classes\nDiscontinuous classes are intervals where gaps exist between the class limits. In such cases, class boundaries are used to close the gaps and ensure continuity.\nExample:\nIf the class intervals are 10 - 19, 20 - 29, 30 - 39, and so on, there is a gap between the end of one interval and the start of the next. The actual range of each interval is defined using class boundaries, which is explained below.\nClass boundaries\nThe raw data in the above example were recorded to the nearest centimeters. Thus, a plant height of 109.5cm would have been recorded as 110cm, a plant height of 119.4 cm would have been recorded as 119cm, while a plant height of 119.5 cm would have been recorded as 120 cm. It can therefore be seen that, the class interval 110 – 119, consists of measurements greater than or equal to 109.5 cm and less than 119.5 cm. The numbers 109.5 and 119.5 are called the lower and upper boundaries of the class interval 110 – 120. The class boundaries of the other class intervals are given below:\n\n\n\nClass boundary and class limits\n\n\nNote:\nNotice that the lower class boundary of the ith class interval is the mean of the lower class limit of the class interval and the upper class limit of the (i-1)th class interval (i = 2, 3, 4, …). For example, in the table above the lower class boundaries of the second and the fourth class intervals are (110 + 109) /2 = 109.5 and (130 + 129)/2 = 129.5 respectively.\nIt can also be seen that the upper class boundary of the ith class interval is the mean of the upper class limit of the class interval and the lower class limit of the (i+1)th class interval (i = 1, 2, 3, …). Thus, in the above table the upper class boundary of the fourth class interval is (139 + 140)/2 = 139.5.\n\n\n\n\n\n\nNote\n\n\n\nFor continuous classes, class limits and boundaries are the same because there are no gaps between intervals. However, for discontinuous classes, boundaries are important as they close gaps and ensure every value belongs to one class.\n\n\nClass mark\nThe mid-point of a class interval is called the class mark or class mid-point of the class interval. It is the average of the upper and lower class limits of the class interval. It is also the average of the upper and lower class boundaries of the class interval. For example, in the table, the class mark of the third class interval was found as follows: class mark =(120+129)/2 = (119.5 + 129.5)/2= 124.5.\nClass width\nFor Continuous Classes:\nThe class width is the difference between the upper and lower class limits of a class interval. Since the class limits and boundaries are the same for continuous classes, the width can also be determined by subtracting two consecutive lower or upper class limits.\nFor Discontinuous Classes:\nThe class width is the difference between the upper and lower class boundaries of a class interval. For discontinuous classes, class boundaries are used to account for gaps, and the width can also be determined by subtracting two consecutive lower or upper class boundaries.\nNote: \nIn the grouped frequency table above with discontinuous classes, the width of the second class interval is calculated as |110 - 119| = 9. It can be observed that the width is the same for all classes. This result can also be obtained by taking the numerical difference between the lower class boundaries of the second and third class intervals.\n\n\n1.14.2 Construction\nStep 1. Decide how many classes you wish to use.\nStep 2. Determine the class width\nStep 3. Set up the individual class limits\nStep 4. Tally the items into the classes\nStep 5. Count the number of items in each class\nConsider the example where an agricultural student measured the lengths of leaves on an oak tree (to the nearest cm). Measurements on 38 leaves are as follows\n9, 16, 13, 7, 8, 4, 18, 10, 17, 18,\n9, 12, 5, 9, 9, 16, 1, 8, 17, 1, 10, 5, 9, 11, 15, 6, 14, 9, 1, 12,\n5, 16, 4, 16, 8, 15, 14, 17\nStep 1. Decide how many classes you wish to use.\nH.A. Sturges provides a formula for determining the approximation number of classes. \\[\\mathbf{k = 1 + 3.322}.\\mathbf{\\log}\\mathbf{N}\\] Number of classes should be greater than calculated k\nIn our example N=38, so k= (1+3.322)×log(38) = (1+3.322)×1.5797 = 6.24 = approx 7\nSo the approximated number of classes should be not less than 6.24 i.e.\\(\\ k^{'}\\) =7\nStep 2. Determine the class width\nGenerally, the class width should be the same size for all classes. C= | max − min|/ k. Class width \\(C^{'}\\)should be greater than calculated C. For this example, C = | 18− 1|/6.24 = 2.72, so approximately class width \\(C^{'} =\\) 3 (Note that k used here is the calculated value using Sturges formula not the approximated).\nStep 3. To set up the individual class limits, we need to find the lower limit only\n\\[L = min - \\frac{C^{'} \\times k^{'} - (max - min)}{2}\\]\nwhere C and k here are final approximated class width and number of classes respectively in our example \\(L = 1 - \\frac{(3 \\times 7) - (18 - 1)}{2}\\)=1-2=-1; since there is no negative values in data = 0. Final frequency table will be as shown in Table 1.1\n\n\n\nTable 1.1: Frequency distribution table\n\n\n\n\n\nClass\nFrequency\n\n\n\n\n0-3\n3\n\n\n3-6\n5\n\n\n6-9\n5\n\n\n9-12\n9\n\n\n12-15\n5\n\n\n15-18\n9\n\n\n18-21\n2\n\n\n\n\n\n\n\n\nEven though the student only measured in whole numbers, the data is continuous, so “4 cm” means the actual value could have been anywhere from 3.5 cm to 4.5 cm.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#cumulative-frequency",
    "href": "intro.html#cumulative-frequency",
    "title": "1  Basics of statistics",
    "section": "1.15 Cumulative frequency",
    "text": "1.15 Cumulative frequency\nIn many situations, we are not interested in the number of observations in a given class interval, but in the number of observations which are less than (or greater than) a specified value. For example, in the above table, it can be seen that 3 leaves have length less than 3.5 cm and 9 leaves (i.e. 3 + 6) have length less than 6.5 cm. These frequencies are called cumulative frequencies. A table of such cumulative frequencies is called a cumulative frequency table or cumulative frequency distribution.\nCumulative frequency is defined as a running total of frequencies. Cumulative frequency can also defined as the sum of all previous frequencies up to the current point. Notice that the last cumulative frequency is equal to the sum of all the frequencies. Two types of cumulative frequencies are Less than Cumulative Frequency (LCF) and Greater than Cumulative Frequency(GCF). LCF is the number of values less than a specified value. GCF is the number of observations greater than a specified value.\nThe specified value for LCF in the case of grouped frequency distribution will be upper limits and for GCF will be the lower limits of the classes. LCF’s are obtained by adding frequencies in the successive classes and GCF are obtained by subtracting the successive class frequencies from the total frequency. see calculated LCF and GCF in Table 1.2 below.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#relative-frequency",
    "href": "intro.html#relative-frequency",
    "title": "1  Basics of statistics",
    "section": "1.16 Relative frequency",
    "text": "1.16 Relative frequency\nIt is sometimes useful to know the proportion, rather than the number, of values falling within a particular class interval. We obtain this information by dividing the frequency of the particular class interval by the total number of observations. Relative frequency of a class is the frequency of class divided by total observations. Relative frequencies all add up to 1. See relative frequency calculated in Table 1.2 .\n\n\n\nTable 1.2: LCF,GCF and Relative frequency\n\n\n\n\n\nClass\nFrequency\nA\nB\nC\n\n\n\n\n0.5 - 3.5\n3\n3\n38\n0.079\n\n\n3.5 - 6.5\n6\n9\n35\n0.158\n\n\n6.5 - 9.5\n10\n19\n29\n0.263\n\n\n9.5 - 12.5\n5\n24\n19\n0.132\n\n\n12.5 - 15.5\n5\n29\n14\n0.132\n\n\n15.5 - 18.5\n9\n38\n9\n0.237\n\n\n\n\n\n\n\n\n \n \n \n\n\n\n\n\n\nQuotes to Inspire\n\n\n\n“Data is the sword of the 21st century, those who wield it well, the Samurai.”\n- Jonathan Rosenberg, former Google SVP\n\n\n\n\n\n\n\nBall, Philip. 2004. Critical Mass. Farrar, Straus; Giroux.\n\n\nGoon, Gupta, A. M., and B Dasgupta. 1983. Fundamentals of Statistics. Vol. I. TheWorld Press.\n\n\nGupta, S. C., and V. K. Kapoor. 1997. Fundamentals of Mathematical Statistics. Sulthan Chand Publications, New Delhi.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Basics of statistics",
    "section": "",
    "text": "actuary: A person who compiles and analyses statistics and uses them to calculate insurance risks and premiums.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of statistics</span>"
    ]
  },
  {
    "objectID": "agstatindia.html",
    "href": "agstatindia.html",
    "title": "2  Statistics on agriculture",
    "section": "",
    "text": "2.1 Compiling crop statistics\nThe agricultural sector accounts for approximately 18% of India’s GDP and employs nearly half of its workforce. Reliable and timely information is vital for planners and policymakers to develop effective agricultural policies and make informed decisions on procurement, storage, public distribution, imports, exports, and other related matters. As such, the collection and management of agricultural statistics hold significant importance.\nThis chapter provides an overview of the system for collecting agricultural statistics in India. While agriculture is a State subject, agricultural statistics fall under the concurrent list, resulting in a decentralised system. State Governments, through their State Agricultural Statistics Authorities (SASAs), play a central role in collecting and compiling agricultural statistics at the State level. At the national level, the Directorate of Economics and Statistics, under the Ministry of Agriculture and Farmers Welfare, is responsible for compiling the data. Other key agencies involved include the National Statistical Office (NSO) and the State Directorates of Economics and Statistics (DESs).\nCrop statistics comprise two key components: the area sown and the average yield.\nWhile area estimates are derived from land revenue systems, yield estimates are obtained through crop estimation surveys.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistics on agriculture</span>"
    ]
  },
  {
    "objectID": "agstatindia.html#compiling-crop-statistics",
    "href": "agstatindia.html#compiling-crop-statistics",
    "title": "2  Statistics on agriculture",
    "section": "",
    "text": "2.1.1 Area statistics\nThe system for collecting area statistics across States and Union Territories (UTs) in India can be broadly classified into three categories:\n\nStates with complete enumeration systems\nThese include States with land records or temporary settlement systems, covering 86% of the states (18 States and 3 UTs).\nStates using sample surveys\nThese are States with no land record system or permanently settled States, representing 9% of the states.\nStates with no developed system for area statistics\nIn these States, the collection is still based on conventional methods such as personal assessment, accounting for 5% of the states.\n\n\n\n2.1.2 Crop yield estimation\nCrop yields are estimated through Crop Cutting Experiments (CCE), which are conducted extensively across the country. The General Crop Estimation Survey (GCES) covers 65 crops, including 51 food crops and 14 non-food crops. Approximately 9 lakh CCEs are carried out annually in India to estimate the yield of key crops such as rice, maize, bajra, groundnut, and sugarcane. These experiments are conducted systematically to ensure accurate and reliable yield data for principal crops.\n\n\n\nSampling Design under General Crop Estimation Survey\n\n\nFinal estimates of crop production are calculated using area figures obtained through complete enumeration and yield rates derived from crop-cutting experiments. These estimates become available only after the harvest. However, to support timely decision-making, the Government requires advance production estimates.\nThe Directorate of Economics and Statistics (DES), under the Ministry of Agriculture and Farmers Welfare, provides advance estimates of crop area and production for key food and non-food crops such as food grains, oilseeds, sugarcane, and fibres. These estimates are issued in four stages:\n\nFirst forecast: Mid-September\n\nSecond forecast: January\n\nThird forecast: Late March\n\nFourth forecast: Late May\n\nIn addition to these forecasts, Final Estimates of crop area and production are published in December. Subsequently, Fully Revised Estimates for all-India crop statistics are released in December of the following crop year.\nAdditionally, information on the structure and characteristics of the agricultural sector is gathered through the Agricultural Census.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistics on agriculture</span>"
    ]
  },
  {
    "objectID": "agstatindia.html#agricultural-census",
    "href": "agstatindia.html#agricultural-census",
    "title": "2  Statistics on agriculture",
    "section": "2.2 Agricultural census",
    "text": "2.2 Agricultural census\nThe Agricultural Census is a comprehensive exercise conducted to gather and analyze data on the structure of the agricultural sector in India. It provides essential information about operational holdings, including their number, area, land use, cropping patterns, and input usage, down to the lowest geographical levels such as villages, tehsils (sub-districts), and districts. This census serves as a statistical framework for planning and conducting future agricultural surveys.\nInitiated in 1970-71, the Agricultural Census is conducted every five years by the Department of Agriculture and Farmers Welfare in collaboration with State and Union Territory administrations. In States with land records, the number and area of operational holdings are collected through complete enumeration, while detailed data on the characteristics of operational holdings are gathered on a sample basis.\nTo date, eleven Agricultural Censuses have been conducted, covering the reference years 1970-71, 1976-77, 1980-81, 1985-86, 1990-91, 1995-96, 2000-01, 2005-06, 2010-11, 2015-16 and 2020-21. The reference period for each census corresponds to the agricultural year, spanning from July to June.\nThe data derived from the Agricultural Census plays a crucial role in policy formulation, resource allocation, and the overall development of the agricultural sector in India.\nAdditional data pertaining to various sectors can be obtained from the sources listed in the Appendix 1\n \n \n \n\n\n\n\n\n\nQuotes to Inspire\n\n\n\n“Statistics is the art of never having to say you’re certain.” – W. Edwards Deming",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistics on agriculture</span>"
    ]
  },
  {
    "objectID": "3graph.html",
    "href": "3graph.html",
    "title": "3  Graphical representation",
    "section": "",
    "text": "3.1 Histogram\nGraphs and diagrams play a vital role in statistics by transforming complex data into clear, visual formats that are easier to interpret and analyze. While frequency distributions in tabular form help organize raw data, graphical representations provide a more intuitive way to understand patterns, trends, and relationships within the data. By converting numbers into visual elements, graphs make it simpler to convey information effectively, making them indispensable tools in research, analysis, and communication. Depending on the nature of the data and the intended purpose, various types of graphs and diagrams can be employed to illustrate key insights. This chapter focuses on the fundamental graphs and charts used in statistics to visually represent data.\nA histogram is a graphical representation used to display the frequency distribution of continuous data. It consists of adjacent rectangles, where:\nUnlike bar charts, histograms have no gaps between the rectangles, emphasizing the continuity of the data. The height of each rectangle represents the frequency for equal-width classes. Histograms are effective tools for visualizing data distribution, identifying patterns, and highlighting skewness or outliers.\nExample 3.1 Table 4.1 displays the frequency distribution of plant heights for a sample of 50 plants. This data can be visualized effectively using a histogram, as shown in Figure 3.1.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Graphical representation</span>"
    ]
  },
  {
    "objectID": "3graph.html#histogram",
    "href": "3graph.html#histogram",
    "title": "3  Graphical representation",
    "section": "",
    "text": "The base of each rectangle lies along the horizontal axis, with the width determined by the class intervals.\n\nThe height of each rectangle is proportional to the frequency of the corresponding class.\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the class intervals are of equal width, the height of each rectangle in a histogram is directly proportional to the class frequency. In such cases, the class frequencies can be used as the heights of the rectangles.\nHowever, when class intervals have varying widths, the height of each rectangle should be proportional to the frequency density, which is calculated as:\n\\[\n\\text{Frequency Density} = \\frac{\\text{Class Frequency}}{\\text{Class Width}}\n\\]\nIn these cases, the frequency density is plotted on the y-axis to ensure that the area of each rectangle accurately represents the frequency of the class. This approach maintains the correct visual representation of the data distribution regardless of the class interval widths.\n\n\n\n\n\n\nTable 3.1: Grouped frequency table of plant heights\n\n\n\n\n\nPlant height (cm)\nFrequency\n\n\n\n\n130 – 140\n3\n\n\n140 – 150\n6\n\n\n150 – 160\n17\n\n\n160 – 170\n13\n\n\n170 – 180\n8\n\n\n180 – 190\n3\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.1: Histogram",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Graphical representation</span>"
    ]
  },
  {
    "objectID": "3graph.html#ogive",
    "href": "3graph.html#ogive",
    "title": "3  Graphical representation",
    "section": "3.2 Ogive",
    "text": "3.2 Ogive\nOgive, also known as the cumulative frequency curve, is a graphical representation that plots cumulative frequencies against class boundaries. The points are typically connected using straight lines, forming a continuous curve. This visualization effectively illustrates the accumulation of frequencies, making it useful for understanding data distribution and determining percentiles or the median.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Graphical representation</span>"
    ]
  },
  {
    "objectID": "3graph.html#types-of-ogives",
    "href": "3graph.html#types-of-ogives",
    "title": "3  Graphical representation",
    "section": "3.3 Types of ogives",
    "text": "3.3 Types of ogives\nThere are two main types of cumulative frequency curves:\n1. Less than ogive\n2. Greater than ogive\nLess than ogive\nThe less than ogive, also known as the less than type cumulative frequency curve, is created by plotting the less than cumulative frequencies against the upper class boundaries. For example, consider the plant height data for 50 plants. By using the upper class limits and their cumulative frequencies, we can construct a smooth curve that provides insights into the data distribution. See Table 3.2, which is constructed from Table 4.1. The less than ogive, shown in Figure 3.2, is drawn using Table 3.2.\n\n\n\nTable 3.2: Upper limit and LCF of plant heights\n\n\n\n\n\nUpper limit\n140\n150\n160\n170\n180\n190\n\n\nLCF\n3\n9\n26\n39\n47\n50\n\n\n\n\n\n\nNote: LCF denotes less than cumulative frequency\n\n\n\n\n\n\nFigure 3.2: Less than Ogive\n\n\n\nGreater than ogive\nThe greater than ogive, also known as the greater than type cumulative frequency curve, is constructed by plotting the greater than cumulative frequencies against the lower class boundaries. In this case, instead of using the upper limits like in the “Less than ogive”, we use the lower class limits and their corresponding cumulative frequencies. This curve helps visualize the cumulative frequency distribution from the highest class down to the lowest, providing insights into the number of observations greater than a specific value. See Table 3.3 constructed from Table 4.1. The greater than ogive, shown in Figure 3.3, is drawn using Table 3.3.\n\n\n\nTable 3.3: Lower limit and GCF of plant heights\n\n\n\n\n\nLower limit\n130\n140\n150\n160\n170\n180\n\n\nGCF\n50\n47\n41\n24\n11\n3\n\n\n\n\n\n\nNote: GCF denotes greater than cumulative frequency\n\n\n\n\n\n\nFigure 3.3: Greater Than Ogive\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIntersection of both less than and greater than ogives gives the median",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Graphical representation</span>"
    ]
  },
  {
    "objectID": "3graph.html#frequency-polygon",
    "href": "3graph.html#frequency-polygon",
    "title": "3  Graphical representation",
    "section": "3.4 Frequency polygon",
    "text": "3.4 Frequency polygon\nA grouped frequency table can also be represented by a frequency polygon, a special type of line graph. To construct it, plot the class frequencies against the corresponding class midpoints and connect successive points with straight lines. The frequency polygon can also be derived by joining the midpoints of a histogram. See Table 3.4, constructed from Table 4.1. The frequency polygon, created using Table 3.4, is shown in Figure 3.4. The relation between frequency polygon and histogram can be seen in Figure 3.5\n\n\n\nTable 3.4: Midpoints and frequencies\n\n\n\n\n\nClass midpoints\n135\n145\n155\n165\n175\n185\n\n\nFrequencies\n3\n6\n17\n13\n8\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.4: Frequency Polygon\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.5: Frequency Polygon and Histogram",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Graphical representation</span>"
    ]
  },
  {
    "objectID": "3graph.html#stem-and-leaf-plot",
    "href": "3graph.html#stem-and-leaf-plot",
    "title": "3  Graphical representation",
    "section": "3.5 Stem-and-leaf plot",
    "text": "3.5 Stem-and-leaf plot\nA stem-and-leaf plot is a graphical device useful for representing a relatively small set of data that takes numerical values. To construct a stem-and-leaf plot, we partition each measurement into two parts: the stem (the leading digits) and the leaf (the trailing digits). This method retains the exact value of each observation, unlike a frequency distribution. It also clearly shows the distribution of data within each group. A stem-and-leaf plot conveys similar information as a histogram, with the added benefit of retaining individual data points. It provides insights into the range, concentration of measurements, and symmetry of the data.\nConsider the example:\n12, 16, 21, 25, 29, 26, 30, 31, 37, 42, 45.\nThe stem-and-leaf plot for this data is shown Figure 3.6\n\n\n\n\n\n\nFigure 3.6: Stem and Leaf plot",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Graphical representation</span>"
    ]
  },
  {
    "objectID": "3graph.html#bar-chart",
    "href": "3graph.html#bar-chart",
    "title": "3  Graphical representation",
    "section": "3.6 Bar chart",
    "text": "3.6 Bar chart\nA bar chart or bar graph is a diagram consisting of a series of horizontal or vertical bars of equal width. The bars represent various categories of the data. There are three types of bar charts, and these are simple bar charts, component bar charts and grouped bar charts.\nSimple bar chart\nIn a simple bar chart, the height (or length) of each bar is equal to the value of category in the y-axis it represents. Table 3.5 presents hypothetical data on coconut production across five districts of Kerala for a specific year. The data represented using barchart is shown in Figure 3.7\n\n\n\nTable 3.5: hypothetical data on coconut production\n\n\n\n\n\nDistrict\nProduction (million nuts)\n\n\n\n\nAlappuzha\n700\n\n\nKannur\n800\n\n\nThrissur\n980\n\n\nErnakulam\n1100\n\n\nWayanad\n1400\n\n\n\n\n\n\nComponent bar chart\nIn a component bar chart, the bar for each category is subdivided into component parts; hence its name. Component bar charts are therefore used to show the division of items into components. Component bar chart is also known as stacked barchart\nFigure 3.8 shows the distribution of sales of agricultural produce from a farm in 1995, 1996 and 1997 and its corresponding component barchart in Figure 3.9.\nThe component bar chart shows the changes of each component over the years as well as the comparison of the total sales between different years.\nGrouped bar chart\nFigure 3.8 can also be represented using a grouped bar chart shown in Figure 3.10. For a grouped bar chart, each category within a group is represented by a bar with a distinct shade or color, allowing for clear comparisons of both within and across groups.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.7: Barchart\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.8: Sales data of agricultural produce\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.9: Component Barchart\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.10: Grouped bar chart",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Graphical representation</span>"
    ]
  },
  {
    "objectID": "3graph.html#histogram-versus-bar-chart",
    "href": "3graph.html#histogram-versus-bar-chart",
    "title": "3  Graphical representation",
    "section": "3.7 Histogram versus bar chart",
    "text": "3.7 Histogram versus bar chart\nTable 3.6 highlights the key differences between histograms and bar charts, two commonly used graphical tools in data visualization. While both employ bars to represent data, they serve distinct purposes and are applied to different types of data. Understanding these differences ensures the correct choice of graph for effectively presenting and interpreting data.\n\n\n\nTable 3.6: Comparison between histogram and barchart\n\n\n\n\n\n\n\n\n\n\nFeature\nHistogram\nBar Chart\n\n\n\n\nMeaning\nA graphical representation using bars to display the frequency of numerical data.\nA pictorial representation using bars to compare different categories of data.\n\n\nPurpose\nDepicts the distribution of continuous (non-discrete) data.\nCompares discrete (categorical) data.\n\n\nType of Data\nQuantitative data.\nCategorical data.\n\n\nBar Spacing\nBars are adjacent with no gaps.\nBars are separated by spaces.\n\n\nGrouping of Elements\nData is grouped into ranges or intervals (bins).\nData is represented as individual categories.\n\n\nBar Order\nBars cannot be reordered.\nBars can be reordered.\n\n\nBar Width\nBar widths may vary.\nBar widths are uniform.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Graphical representation</span>"
    ]
  },
  {
    "objectID": "3graph.html#pie-charts",
    "href": "3graph.html#pie-charts",
    "title": "3  Graphical representation",
    "section": "3.8 Pie charts",
    "text": "3.8 Pie charts\nA pie chart is a circular graph divided into sectors, each sector representing a different value or category. The angle of each sector of a pie chart is proportional to the value of the part of the data it represents. The bar chart is more precise than the pie chart for visual comparison of categories with similar relative frequencies.\nSteps for constructing a pie chart\n\nFind the sum of the category values.\n\nCalculate the angle of the sector for each category, using the following formula.Angle of the sector for category A = \\(\\frac{\\text{value of category A}}{\\text{sum of category values}} \\times 360\\)\n\nConstruct a circle and mark the centre.\n\nUse a protractor to divide the circle into sectors, using the angles obtained in step 2.\n\nLabel each sector clearly.\n\nTable 3.7 presents hypothetical data on the production of different commodities in India during a particular year. Pie chart base on this data is shown in Figure 3.11\n\n\n\nTable 3.7: Hypothetical data on the production of different commodities\n\n\n\n\n\nCommodities\nProduction(tonnes)\nAngle\n\n\n\n\nWheat\n27000\n(27000/81000)×360= 120\n\n\nGrams\n22500\n100\n\n\nMaize\n13500\n60\n\n\nRice\n6750\n30\n\n\nSugar\n11250\n50\n\n\nTotal\n81000\n360\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.11: Piechart",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Graphical representation</span>"
    ]
  },
  {
    "objectID": "3graph.html#boxplot",
    "href": "3graph.html#boxplot",
    "title": "3  Graphical representation",
    "section": "3.9 Boxplot",
    "text": "3.9 Boxplot\nA boxplot, also known as a box-and-whisker plot, visually represents the five-number summary of a dataset: the minimum value, first quartile, median, third quartile, and maximum value. These key statistics provide insights into the dataset’s central tendency, spread, and potential outliers. Quartiles and the median, explained in detail in Section 5.5, are critical components of this summary.\nIn a boxplot, a rectangular box spans from the first quartile (Q1) to the third quartile (Q3), with a vertical line inside the box indicating the median. Whiskers extend from each end of the box to the dataset’s minimum and maximum values, providing a clear picture of the range and variability.\nFigure 3.12 below shows the parts of a box plot\n\n\n\n\n\n\nFigure 3.12: Anatomy of box plot\n\n\n\nIn a boxplot, the minimum value is defined as \\(Q_{1}- 1.5\\times IQR\\), and the maximum value is \\(Q_{3}+ 1.5\\times IQR\\), where \\(Q_{1}\\) and \\(Q_{3}\\) represent the first and third quartiles, and IQR stands for the interquartile range. Any data points falling below the minimum or above the maximum are considered outliers.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Graphical representation</span>"
    ]
  },
  {
    "objectID": "3graph.html#advanced-visualization",
    "href": "3graph.html#advanced-visualization",
    "title": "3  Graphical representation",
    "section": "3.10 Advanced visualization",
    "text": "3.10 Advanced visualization\nWhile this book focuses on basic plots and charts, significant advancements have been made in the field of data visualization. New types of graphs and charts have been developed to help in more effective representation and communication of data. Although a detailed discussion of these advanced graphs is beyond the scope of this book, we provide an overview of some common and recently developed types for reference. For more detailed information, you can explore resources such as The R Graph Gallery.\nIt is important to be aware of the wide variety of visualization tools available, as they can enhance your understanding of data and improve your ability to communicate insights clearly. From Figure 3.12 to 3.23 you can see a few popular and advanced graph types widely used in modern data analysis.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.13: Box Plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.14: Violin Plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.15: Lollipop Plot\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.16: Dendrogram\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.17: Network Graph\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.18: Heat Map\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.19: Circular Bar Plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.20: Sankey Diagram\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.21: Ridgeline Plot\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.22: Chord Diagram\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.23: Density Plot\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.24: Stream Graph\n\n\n\n\n\n\n\n\n\n\n\n\nTimeless Insights\n\n\n\nHistorical facts here\n\n\n\n\n\n\n\n\nQuotes to Inspire\n\n\n\n“Statistics is the grammer of science”\n- Karl Pearson",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Graphical representation</span>"
    ]
  },
  {
    "objectID": "central1.html",
    "href": "central1.html",
    "title": "4  Central tendency I",
    "section": "",
    "text": "4.1 Arithmetic mean\nIn the previous chapter, you explored how data can be summarized using tables and visually presented through graphs, enabling important features to be highlighted effectively. In this chapter, we shift our focus to statistical measures that describe the characteristics of a dataset.\nOne key aspect of data analysis is identifying a single value that represents the overall dataset. This is where measures of central tendency come into play. These are summary statistics that capture the center or typical value of a dataset, providing a concise numerical summary.\nThere are five commonly used averages: mean, median, and mode, collectively referred to as simple averages, and geometric mean and harmonic mean, known as special averages. In addition to these, there are positional averages, such as quartiles, deciles, and percentiles, which are determined based on the position of values within an ordered dataset. These measures provide insights into the central value and distribution of the data, making them fundamental tools for understanding and interpreting data patterns.\nIn this section, we will focus on simple averages, with a detailed discussion on positional averages and special averages following later.\nRequisites of a Good Measure of Central Tendency:\nThe main objectives of Measure of Central Tendency:\nThis is what people usually intend when they say “average”. Arithmetic mean or simply the mean of a variable is defined as the sum of the observations divided by the number of observations. Mean of set of numbers \\(x_{1\\ },x_{2},\\ldots,x_{n}\\) is denoted as \\(\\overline{x}\\). It is given by the formula\n\\[\\overline{x} = \\frac{x_{1} + x_{2} + \\ldots + x_{n}}{n}\\]\n\\[= \\frac{1}{n}\\sum_{i = 1}^{n}x_{i} \\tag{4.1}\\]\nExample 4.1 Find the mean of the numbers 2, 4, 7, 8, 11, 12\n\\[\\overline{x} = \\frac{2 + 4 + 7 + 8 + 11 + 12}{6} = \\frac{44}{6} = 7.33\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Central tendency I</span>"
    ]
  },
  {
    "objectID": "central1.html#arithmetic-mean",
    "href": "central1.html#arithmetic-mean",
    "title": "4  Central tendency I",
    "section": "",
    "text": "4.1.1 Mean of ungrouped frequency distribution\nDirect method\nIf the numbers \\(x_{1\\ },x_{2},\\ldots,x_{n}\\) occur with frequencies \\(f_{1\\ },f_{2},\\ldots,f_{n}\\) respectively then\n\\[\\overline{x} = \\frac{x_{1}f_{1} + x_{2}f_{2\\ \\ } + \\ldots + x_{n}f_{n}}{f_{1} + f_{2} + \\ldots f_{n}}\\]\n\\[= \\frac{\\sum_{i = 1}^{n}{f_{i}x_{i}}}{\\sum_{i = 1}^{n}f_{i}} \\tag{4.2}\\]\nExample 4.2 Table 4.1 below shows the plant height of 50 plants. Find the mean plant height.\n\n\n\nTable 4.1: Plant height of 50 plants\n\n\n\n\n\nPlant height(cm)\n159\n160\n161\n162\n163\n\n\nFrequency\n3\n9\n23\n11\n4\n\n\n\n\n\n\nSolution 4.2\nThe calculation can be arranged as shown\n\n\n\nTable 4.2: Solution using direct method\n\n\n\n\n\n\n\n\n\n\nPlant height(x)\nFrequency(f)\nfx\n\n\n\n\n159\n3\n477\n\n\n160\n9\n1440\n\n\n161\n23\n3703\n\n\n162\n11\n1782\n\n\n163\n4\n652\n\n\n\n\\(\\sum_{i = 1}^{n}f_{i}\\)= 50\n\\(\\sum_{i = 1}^{n}{f_{i}x_{i}}\\)= 8054\n\n\n\n\n\n\n\\(\\overline{x} = \\frac{\\sum_{i = 1}^{n}{f_{i}x_{i}}}{\\sum_{i = 1}^{n}f_{i}} = \\frac{8054}{50}\\)= 161.08 cm\nAssumed mean method (Indirect method)\nThe amount of computation involved above can be reduced by using the following formula:\n\\[\\overline{x} = A + \\frac{\\sum_{i = 1}^{n}{f_{i}d_{i}}}{\\sum_{i = 1}^{n}f_{i}} \\tag{4.3}\\]\nWhere \\(A\\) is the assumed mean, which can be any value in x. \\(d_{i} = x_{i} - A\\), \\(f_{i}\\) is the frequency of \\(x_{i}\\)\nConsider the Table 4.1\nlet \\(A\\) = 161; it can be any number in x\n\n\n\nTable 4.3: Solution using assumed mean method\n\n\n\n\n\n\n\n\n\n\n\nPlant height(x)\nFrequency(f)\n\\(d_i = x_i - 161\\)\n\\(f_i d_i\\)\n\n\n\n\n159\n3\n-2\n-6\n\n\n160\n9\n-1\n-9\n\n\n161\n23\n0\n0\n\n\n162\n11\n1\n11\n\n\n163\n4\n2\n8\n\n\n\n\\(\\sum_{i = 1}^{n}f_{i}= 50\\)\n\n\\(\\sum_{i = 1}^{n}{f_{i}d_{i}}\\)= 4\n\n\n\n\n\n\nusing Equation 4.3, \\(\\overline{x} = 161 + \\frac{4}{50}\\) = 161.08 cm\nThe mean plant height is 161.08 cm\n\n\n4.1.2 Mean of grouped frequency distribution\nDirect method\nThe mean for grouped data is obtained from the following formula:\n\\[\\overline{x} = \\frac{\\sum_{i = 1}^{k}{f_{i}x_{i}}}{n} \\tag{4.4}\\]\nWhere \\(x_{i}\\) = the mid-point of ith class (ith class mark); \\(f_{i}\\)= the frequency of ith class; \\(n\\) = the sum of the frequencies or total frequencies in a sample. Note that i =1,2…, k, i.e. there are k classes.\nExample 4.3 Table 4.4 shows the distribution of the marks scored by 60 students in a Maths examination. Find the mean mark.\n\n\n\nTable 4.4: Distribution of the marks scored by 60 students\n\n\n\n\n\nMark (%)\n60-65\n65-70\n70-75\n75-80\n80-85\n\n\nNumber of students\n2\n15\n25\n14\n4\n\n\n\n\n\n\nSolution 4.3\nThe solution can be arranged as shown\n\n\n\nTable 4.5: Mean of grouped frequency table using direct method\n\n\n\n\n\n\n\n\n\n\n\nMarks\nClass mark(\\({x}_{i}\\))\nFrequency(\\({f}_{i}\\))\n\\({f}_{i}{x}_{i}\\)\n\n\n\n\n60-65\n62.5\n2\n125\n\n\n65-70\n67.5\n15\n1012.5\n\n\n70-75\n72.5\n25\n1812.5\n\n\n75-80\n77.5\n14\n1085\n\n\n80-85\n82.5\n4\n330\n\n\n\n\n\\(\\sum_{i = 1}^{n}f_{i}\\)= 60\n\\(\\sum_{i = 1}^{n}{f_{i}x_{i}}\\)= 4365\n\n\n\n\n\n\n\\(\\overline{x} = \\frac{\\sum_{i = 1}^{n}{f_{i}x_{i}}}{\\sum_{i = 1}^{n}f_{i}} = \\frac{4365}{60}\\)= 72.75\nThe mean mark is 72.75%\nCoding Method or Indirect method\nIf all the class intervals of a grouped frequency distribution have equal size \\(C\\) (class width); then the following formula can be used instead of direct method above. This formula makes calculations easier.\n\\[\\overline{x} = A + C\\frac{\\sum_{i = 1}^{n}{f_{i}u_{i}}}{\\sum_{i = 1}^{n}f_{i}} \\tag{4.5}\\]\nWhere \\(A\\) is the class mark with the highest frequency, \\(u_{i} = \\frac{x_{i} - A}{C}\\), \\(f_{i}\\) is the frequency of \\(x_{i}\\), C is the class width.\nThis is called the “coding” method for computing the mean. It is a very short method and should always be used for finding the mean of a grouped frequency distribution with equal class widths.\nConsider the Table 4.4 of the Example 4.3.\n\\(A\\)=72.5, class mark with highest frequency; \\(C\\) =5\n\n\n\nTable 4.6: Solution using coding method\n\n\n\n\n\n\n\n\n\n\n\n\nMarks\nClass mark(\\({x}_{i}\\))\nFrequency(\\({f}_{i}\\))\n\\[{u}_{i}=\\frac{x_i- 72.5}{5}\\]\n\\[{f}_{i}{u}_{i}\\]\n\n\n\n\n60-65\n62.5\n2\n-2\n-4\n\n\n65-70\n67.5\n15\n-1\n-15\n\n\n70-75\n72.5\n25\n0\n0\n\n\n75-80\n77.5\n14\n1\n14\n\n\n80-85\n82.5\n4\n2\n8\n\n\n\n\n\\(\\sum_{i = 1}^{k}f_{i}\\)= 60\n\n\\(\\sum_{i = 1}^{k}{f_{i}u_{i}}\\)=3\n\n\n\n\n\n\nusing Equation 4.5, \\(\\overline{x} = 72.5 + 5 \\times \\left( \\frac{3}{60} \\right)\\)= 72.75\nThe mean mark is 72.75%\nMerits and demerits of arithmetic mean\nMerits\n\nIt is rigidly defined.\nIt is easy to understand and easy to calculate.\nIf the number of items is sufficiently large, it is more accurate and more reliable.\nIt is a calculated value and is not based on its position in the series.\nIt is possible to calculate even if some of the details of the data are lacking.\nOf all averages, it is affected least by fluctuations of sampling.\nIt provides a good basis for comparison.\n\nDemerits\n\nIt cannot be obtained by inspection nor located through a frequency graph.\nIt cannot be in the study of qualitative phenomena not capable of numerical measurement i.e. Intelligence, beauty, honesty etc.\nIt can ignore any single item only at the risk of losing its accuracy.\nIt is affected very much by extreme values.\nIt cannot be calculated for open-end classes.\nIt may lead to fallacious conclusions, if the details of the data from which it is computed are not given.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Central tendency I</span>"
    ]
  },
  {
    "objectID": "central1.html#the-median",
    "href": "central1.html#the-median",
    "title": "4  Central tendency I",
    "section": "4.2 The median",
    "text": "4.2 The median\nThe median is the middle value in a set of data when the values are arranged in order from smallest to largest. If there is an odd number of values, the median is the one in the middle, with half of the values smaller and half larger. If there is an even number of values, the median is the average of the two middle values. The median is a positional measure, which means it depends on the order of the data, not the actual values. It helps to find the central point of the data, especially when there are extreme values or outliers that could affect the average.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Central tendency I</span>"
    ]
  },
  {
    "objectID": "central1.html#median-of-ungrouped-or-raw-data",
    "href": "central1.html#median-of-ungrouped-or-raw-data",
    "title": "4  Central tendency I",
    "section": "4.3 Median of ungrouped or raw data",
    "text": "4.3 Median of ungrouped or raw data\nArrange the given n observations \\(x_{1\\ },x_{2},\\ldots,x_{n}\\) in ascending order. If the number of values is odd, median is the middle value. If the number of values is even, median is the mean of middle two values.\nArrange data in ascending then use the following formula\nWhen n is odd, Median = Md =\\(\\left( \\frac{n + 1}{2} \\right)^{\\text{th}}\\)value\nWhen n is even, Median = Md =\\({\\text{Average of}\\left( \\frac{n}{2} \\right)^{th}\\text{and }\\left( \\frac{n}{2} + 1 \\right)}^{\\text{th}}\\)value\nExample 4.4 Find the median of each of the following sets of numbers.\n\\(a)\\) 12, 15, 22, 17, 20, 26, 22, 26, 12\n\\(b)\\) 4, 7, 9, 10, 5, 1, 3, 4, 12, 10\nSolution 4.4\n\\(a)\\) Arranging the data in an increasing order of magnitude, we obtain 12, 12, 15, 17, 20, 22, 22, 26, 26. Here, N = 9 is odd, and so, median =\\(\\left( \\frac{9 + 1}{2} \\right)^{\\text{th}}\\)= 5th ordered observation = 20.\n\n\n\n\n\n\nNote\n\n\n\nIf a number is repeated, we still count it the number of times it appears when we calculate the median.\n\n\n\\(b)\\) Arranging the data in an increasing order of magnitude, we obtain 1, 3, 4, 4, 5, 7, 9, 10, 10, 12. Here, N = 10 is an even number and so median = \\(\\frac{1}{2}\\){5th ordered observation + 6th ordered observation} = \\(\\frac{1}{2}\\left( 5 + 7 \\right) = 6\\).\n\n\n\n\n\n\nNote\n\n\n\nYou can see in each case, the median divides the distribution into two equal parts, with 50% of the observations greater than it and the other 50% less than it.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Central tendency I</span>"
    ]
  },
  {
    "objectID": "central1.html#median-of-ungrouped-frequency-distribution",
    "href": "central1.html#median-of-ungrouped-frequency-distribution",
    "title": "4  Central tendency I",
    "section": "4.4 Median of ungrouped frequency distribution",
    "text": "4.4 Median of ungrouped frequency distribution\nThe median is the middle number is an ordered set of data. In a frequency table, the observations are already arranged in an ascending order. We can obtain the median by looking for the value in the middle position.\nOdd number of observations\nWhen the number of observations (n) is odd, then the median is the value at the \\(\\left( \\frac{n + 1}{2} \\right)^{\\text{th}}\\) positional value. For that we use less than cumulative frequency.\nExample 4.5: The Table 4.7 shows the frequency of the score obtained in a mathematics quiz. Find the median score.\n\n\n\nTable 4.7: Score obtained in a mathematics quiz\n\n\n\n\n\nScore\n0\n1\n2\n3\n4\n\n\nFrequency\n3\n4\n7\n6\n3\n\n\n\n\n\n\nSolution 4.5:\nTotal frequency = 3 + 4 + 7 + 6 + 3 = 23 (odd number). Since the number of scores is odd, the median is at \\(\\left( \\frac{23 + 1}{2} \\right)^{\\text{th}} =\\) 12th position.\n\n\n\nTable 4.8: Less than cumulative frequency of the scores in mathematics quiz\n\n\n\n\n\nScore\n0\n1\n2\n3\n4\n\n\nFrequency\n3\n4\n7\n6\n3\n\n\nless than cumulative frequency\n3\n7\n14\n20\n23\n\n\n\n\n\n\nTo find out the 12th position, we use less than cumulative frequencies in Table 4.8 which helps us track how many values are less than or equal to each score. In the table, the less than cumulative frequency for the score 0 is 3 (meaning the first 3 values are 0), for the score 1 is 7 (meaning the first 7 values are 0 and 1), and for the score 2 is 14 (meaning the first 14 values are 0, 1, and 2). If we list the data in order, it would look like this: 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2. (no need to list, this is just for reader’s understanding, less than cumulative frequency is enough).\nNow, we need to find where the 12th value falls. The 12th value is between the 7th and 14th values, so based on less than cumulative frequency it is clear that 12th value is 2. So the median is 2.\nEven number of observations\nWhen the number of observations is even, then the median is the average of \\({\\left( \\frac{n}{2} \\right)^{th}\\text{and}\\left( \\frac{n}{2} + 1 \\right)}^{\\text{th}}\\) position values.\nExample 4.6: The Table 4.9 is a frequency table of the marks obtained in a competition. Find the median score.\n\n\n\nTable 4.9: Distribution of marks obtained in a competition.\n\n\n\n\n\nMark\n0\n1\n2\n3\n4\n\n\nFrequency\n11\n9\n5\n10\n15\n\n\n\n\n\n\nSolution 4.6:\nTotal frequency = 11 + 9 + 5 + 10 + 15 = 50 (even number). Since the number of scores is even, the median is at the average of the values in \\({\\left( \\frac{n}{2} \\right)^{th} = 25\\ and\\ \\left( \\frac{n}{2} + 1 \\right)}^{\\text{th}} = 26\\) positions. To find out the 25th position and 26th position, we add up the frequencies as shown:\n\n\n\nTable 4.10: Less than cumulative frequency of marks obtained.\n\n\n\n\n\nMark\n0\n1\n2\n3\n4\n\n\nFrequency\n11\n9\n5\n10\n15\n\n\nless than cumulative frequency\n11\n20\n25\n35\n50\n\n\n\n\n\n\nThe mark at the 25th position is 2 and the mark at the 26th position is 3. The median is the average of the scores at 25th and 26th positions = \\(\\frac{2 + 3}{2} = 2.5\\)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Central tendency I</span>"
    ]
  },
  {
    "objectID": "central1.html#median-of-grouped-frequency-distribution",
    "href": "central1.html#median-of-grouped-frequency-distribution",
    "title": "4  Central tendency I",
    "section": "4.5 Median of grouped frequency distribution",
    "text": "4.5 Median of grouped frequency distribution\nThe exact value of the median of a grouped data cannot be obtained because the actual values of a grouped data are not known. For a grouped frequency distribution, the median is in the class interval which contains the \\(\\left( \\frac{N}{2} \\right)^{\\text{th}}\\)ordered observation, where \\(N\\) is the total number of observations. This class interval is called the median class. The median of a grouped frequency distribution can be estimated by either of the following two methods:\nLinear interpolation method\nThe median of a grouped frequency distribution can be estimated by linear interpolation. We assume that the observations are evenly spread through the median class. The median can then be computed by using the following formula:\n\\[Median = L + \\left( \\frac{\\frac{1}{2}N - F}{f_{m}} \\right)C \\tag{4.6}\\]\nwhere \\(N\\) = total number of observations, \\(L\\) = lower limit of the median class, \\(F\\) = sum of all frequencies below L(cumulative frequency), \\(f_{m}\\) = frequency of the median class, \\(C\\) = class width of the median class.\nEstimation from cumulative frequency curve\nThe median of a grouped frequency distribution can be estimated from a cumulative frequency curve. A horizontal line is drawn from the point \\(\\frac{\\text{N}}{2}\\) on the vertical axis to meet the cumulative frequency curve. From the point of intersection, a vertical line is dropped to the horizontal axis. The value on the horizontal axis is equal to the median.\n\n\n\nmedian from a cumulative frequency curve\n\n\nExample 4.7 Table 4.11 below gives the distribution of the heights of 60 students in a senior high school. Find the median height of the students\n\n\n\nTable 4.11: Distribution of heights of 60 students\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeight(cm)\n145-150\n150-155\n155-160\n160-165\n165-170\n170-175\n\n\nNumber of students\n3\n9\n16\n18\n10\n4\n\n\n\n\n\n\nSolution 4.7\n(i) Linear interpolation method\n\\(N\\) = 60 (Sum of frequencies)\nMedian class= class interval which contains the \\(\\left( \\frac{N}{2} \\right)^{\\text{th}}\\)ordered observation; here \\(\\left( \\frac{60}{2} \\right)^{\\text{th}} =\\) 30th observation. Before the class 160-165 there are 3+9+16=28 observations so 30th observation will be in the class 160-165, therefore it is the median class.\n\\(L\\) = lower limit of the median class =160\n\\(F\\) = sum of all frequencies below 160(cumulative frequency) = 16+9+3= 28\n\\(f_{m}\\) = frequency of the median class=18\n\\(C\\) = class width of the median class=5\nusing Equation 4.6, \\(median = 160 + \\left( \\frac{\\frac{1}{2}60 - 28}{18} \\right)5\\) = 160.56\n(ii) From a cumulative frequency curve\n\n\nMerits and demerits of median\nMerits\n\nMedian is not influenced by extreme values because it is a positional average.\nMedian can be calculated in case of distribution with open-end intervals.\nMedian can be located even if the data are incomplete.\n\nDemerits\n\nA slight change in the series may bring drastic change in median value.\nIn case of even number of items or continuous series, median is an estimated value other than any value in the series.\nIt is not suitable for further mathematical treatment except its use in calculating mean deviation.\nIt does not take into account all the observations.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Central tendency I</span>"
    ]
  },
  {
    "objectID": "central1.html#the-mode",
    "href": "central1.html#the-mode",
    "title": "4  Central tendency I",
    "section": "4.6 The mode",
    "text": "4.6 The mode\nThe mode of a set of data is the value which occurs with the greatest frequency. The mode is therefore the most frequently occuring value in a dataset. The mode is an important measure in case of qualitative data. The mode can be used to describe both quantitative and qualitative data.\n\n4.6.1 Mode of ungrouped or raw data\nFor ungrouped data or a series of individual observations, mode is often found by mere inspection.\nExample 4.8\n\\(a)\\) The modes of 1, 2, 2, 2, 3 is 2.\n\\(b)\\) The modes of 2, 3, 4, 4, 5, 5 are 4 and 5.\n\\(c)\\) The mode does not exist when every observation has the same frequency. For example, the following sets of data have no modes: (i) 3, 6, 8, 9; (ii) 4, 4, 4, 7, 7, 7, 9, 9, 9.\n\n\n\n\n\n\nNote\n\n\n\nIt can be seen that the mode of a distribution may not exist, and even if it exists, it may not be unique. Distributions with a single mode are referred to as unimodal. Distributions with two modes are referred to as bimodal. Distributions may have several modes, in which case they are referred to as multimodal.\n\n\nExample 4.9 20 patients selected at random had their blood groups determined. The results are given in the Table 4.12\n\n\n\nTable 4.12: Blood group of 20 patients\n\n\n\n\n\nBlood group\nA\nAB\nB\nO\n\n\nNo. of patients\n2\n4\n6\n8\n\n\n\n\n\n\nThe blood group with the highest frequency is O. The mode of the data is therefore blood group O. We can say that most of the patients selected have blood group O. Notice that the mean and the median cannot be applied to the data. This is because the variable “blood group” cannot take numerical values. However, it can be seen that the mode can be used to describe both quantitative and qualitative data.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Central tendency I</span>"
    ]
  },
  {
    "objectID": "central1.html#mode-of-grouped-data",
    "href": "central1.html#mode-of-grouped-data",
    "title": "4  Central tendency I",
    "section": "4.7 Mode of grouped data",
    "text": "4.7 Mode of grouped data\nMode of a grouped frequency distribution can be found out using the formula below.\n\\[mode = L + \\left( \\frac{f_{m}-f_{p}}{2f_{m}-f_{p} - f_{s}} \\right)C \\tag{4.7}\\]\nLocate the highest frequency the class corresponding to that frequency is called the modal class.\nWhere, \\(L\\) = lower limit of the modal class; \\(f_{m}\\) = the frequency of modal class; \\(f_{p}\\)= the frequency of the class preceding the modal class; \\(f_{s}\\)= the frequency of the class succeeding the modal class and \\(C\\) = class interval\nExample 4.10 For the frequency distribution of weights of sorghum ear-heads given in Table 4.13 below. Calculate the mode.\n\n\n\nTable 4.13: frequency distribution of weights of sorghum ear heads\n\n\n\n\n\nWeights of ear heads (g)\nNo of ear heads (f)\n\n\n\n\n60-80\n22\n\n\n80-100\n38\n\n\n100-120\n45\n\n\n120-140\n35\n\n\n140-160\n20\n\n\n\n\n\n\nModal class is 100-120, since it is the class with highest frequency.\nUsing Equation 4.7 mode is calculated as below.\n\\(mode = 100 + \\left( \\frac{45-35}{90-38-35} \\right)20 =\\) 111.76\nMode using Histogram\nConsider the figure below. The modal class is the class interval which corresponds to rectangle \\(\\text{ABCD}\\). An estimate of the mode of the distribution is the abscissa of the point of intersection of the line segments \\(\\overline{\\text{AE}}\\) and \\(\\overline{\\text{BF}}\\) in the figure.\n\nMerits and Demerits of Mode\nMerits\n\nIt is readily comprehensible and easy to compute. In some case it can be computed merely by inspection.\nIt is not affected by extreme values. It can be obtained even if the extreme values are not known.\nMode can be determined in distributions with open classes.\nMode can be located on the graph also.\nMode can be used to describe both quantitative and qualitative data.\n\nDemerits\n\nThe mode is not unique. That is, there can be more than one mode for a given set of data.\nThe mode of a set of data may not exist.\nIt is not based upon all the observation.\n\n\n\n\n\n\n\nHistorical Insights\n\n\n\nAncient wall measuring with the mode!\nBack in the 5th century BCE, the Athenians used a clever “statistical hack” to plan their siege of Platea. Soldiers counted bricks in an unplastered section of the wall multiple times, and the most frequent count (what we now call the mode) was taken as the best estimate. They then multiplied this by the height of a brick to calculate the wall’s height and build ladders tall enough to scale it. Problem-solving with statistics!\nAsrtonomy and the mean\nAlthough the Greeks knew the concept of the arithmetic mean, it wasn’t generalized for multiple values until the 16th century. Simon Stevin’s invention of the decimal system in 1585 made it much easier to calculate. Astronomer Tycho Brahe was one of the first to use the mean, reducing errors in his estimates of celestial body locations.\nNavigation and the median\nThe concept of the median first appeared in 1599 in Edward Wright’s book on navigation, Certaine errors in navigation. Wright used it to determine the most likely value in a series of compass readings. Later, in 1669, Christiaan Huygens noticed the difference between the mean and the median while working with Graunt’s tables. It’s amazing how these early navigators and mathematicians paved the way for the stats we use today.\n\n\n\n\n\n\n\n\nQuotes to Inspire\n\n\n\n“If the statistics are boring, you’ve got the wrong numbers”:- Edward R. Tufte",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Central tendency I</span>"
    ]
  },
  {
    "objectID": "central2.html",
    "href": "central2.html",
    "title": "5  Central tendency II",
    "section": "",
    "text": "5.1 Geometric mean\nWhile simple averages like mean, median, and mode are widely used to summarize data, certain situations call for more specialized measures to capture the essence of a dataset. Special averages, including the geometric mean and harmonic mean, are tailored for specific contexts where the nature of the data or the relationships between data points require a different approach.\nThe geometric mean (GM) is a specialized measure of central tendency, particularly suited for datasets involving growth rates, ratios, or percentages, such as population growth, investment returns, or interest rates. Unlike the arithmetic mean, which calculates the average by summing values, the geometric mean finds the average by multiplying values and then taking the root (typically the nth root for n values).\nThis approach captures the compounding effects present in the data, making the geometric mean an essential tool for accurately summarizing proportional changes or rates over time. Its utility lies in providing a more representative measure for datasets where changes are multiplicative rather than additive.\nThe geometric mean of a series containing n observations is the nth root of the product of the values. If \\(x_{1},x_{2},\\ldots, x_{n}\\) are observations then\n\\[GM = \\sqrt[n]{\\prod_{i=1}^{n}x_{i}} \\tag{5.1}\\]\nwhere \\(\\prod_{i=1}^{n} x_i\\) means the product of \\(x_{1},x_{2},\\ldots, x_{n}\\)\n\\[= \\left( x_1 x_2 \\cdots x_n \\right)^{\\frac{1}{n}}\\]\n\\[\\log \\text{GM} = \\frac{1}{n} \\log \\left( x_1 x_2 \\cdots x_n \\right)\\]\n\\[= \\frac{1}{n} \\left( \\log x_1 + \\log x_2 + \\cdots + \\log x_n \\right)\\]\n\\[= \\frac{\\sum_{i=1}^{n} \\log x_i}{n} \\tag{5.2}\\]\n\\[\\text{GM} = \\text{Antilog} \\left( \\frac{\\sum_{i=1}^{n} \\log x_i}{n} \\right) \\tag{5.3}\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Central tendency II</span>"
    ]
  },
  {
    "objectID": "central2.html#geometric-mean",
    "href": "central2.html#geometric-mean",
    "title": "5  Central tendency II",
    "section": "",
    "text": "5.1.1 Geometric mean for frequency table\n\\[\\text{GM} = \\text{Antilog} \\left( \\frac{\\sum_{i=1}^{k} f_i \\log x_i}{n} \\right) \\tag{5.4}\\]\nwhere \\(x_{i}\\) is the ith value in the dataset and for a grouped frequency table \\(x_{i}\\) will be the midpoint of the ith class interval calculated as the average of upper and lower limit, \\(f_{i}\\) is the frequency of the ith value or class , k is the number of classes.\nExample 5.1 If the weight of sorghum ear heads are 45, 60, 48, 100, 65 gms. Find the Geometric mean?\n\n\n\nTable 5.1: log values of sorghum ear head weights\n\n\n\n\n\nWeight of ear head (x)\nlog(x)\n\n\n\n\n45\n1.653\n\n\n60\n1.778\n\n\n48\n1.681\n\n\n100\n2.000\n\n\n65\n1.813\n\n\nTotal\n8.926\n\n\n\n\n\n\nSolution 5.1\nHere n =5\nusing Equation 5.3\n\\[=\\text{Antilog}\\left( \\frac{8.926}{5} \\right) \\]\n\\[ =\\text{Antilog}(1.785) = 60.95\\] note: here \\(\\text{Antilog}\\left( x \\right) = 10^{x}\\) i.e. \\[\\text{Antilog}\\left( 1.785 \\right) = \\ 10^{1.785} = 60.95\\]\nExample 5.2 Geometric mean of a frequency distribution\n\n\n\nTable 5.2: Frequency distribution and log for GM calculation\n\n\n\n\n\nWeight of ear head (x)\nFrequency(f)\nlog(x)\nf.log(x)\n\n\n\n\n45\n5\n1.653\n8.266\n\n\n60\n4\n1.778\n7.113\n\n\n48\n6\n1.681\n10.087\n\n\n100\n8\n2.000\n16.000\n\n\n65\n9\n1.813\n16.316\n\n\nTotal\n32\n\n57.782\n\n\n\n\n\n\nSolution 5.2\nHere n =32\nusing Equation 5.4\n\\[{\\sum_{i = 1}^{k}{{f_{i}\\log}x_{i}} = 57.782\n}\\]\n\\[{\\text{GM} = \\ Antilog\\left( \\frac{57.782}{32} \\right)  }\\]\n\\[{= Antilog\\left( 1.8056 \\right)= 10^{1.8056} = 63.92}\\]\nExample 5.3 Geometric mean of a grouped frequency distribution\n\n\n\nTable 5.3: Geometric mean calculation for grouped frequency table\n\n\n\n\n\nClass\nMid value (x)\nFrequency(f)\nlog(x)\nf.log(x)\n\n\n\n\n60-80\n70\n5\n1.845\n9.225\n\n\n80-100\n90\n4\n1.954\n7.817\n\n\n100-120\n110\n6\n2.041\n12.248\n\n\n120-140\n130\n8\n2.114\n16.912\n\n\n140-160\n150\n9\n2.176\n19.585\n\n\n\nTotal\n32\n\n65.787\n\n\n\n\n\n\nSolution 5.3\nHere n =32\nusing Equation 5.4\n\\[{\\sum_{i = 1}^{k}{{f_{i}\\log}x_{i}} = 65.787}\\] \\[{\\text{GM} = \\ Antilog\\left( \\frac{65.787}{32} \\right)}\\] \\[{= Antilog\\left( 2.0558 \\right) = 10^{2.0558} = 113.71}\\]\nMerits and demerits of geometric mean\nMerits\n\nIt is rigidly defined.\nIt is based on all the observations of the series.\nIt is suitable for measuring the relative changes.\nIt gives more weights to the small values and less weight to the large values.\nIt is used in averaging the ratios, percentages and in determining the rate gradual increase and decrease.\nIt is capable of further algebraic treatment.\n\nDemerits\n\nIt is not easy to understand.\nIt is difficult to calculate.\nIt cannot be calculated, if the number of negative values is odd.\nIt cannot be calculated, if any value of a series is zero.\nAt times it gives a value which may not be found in the series or impractical.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Central tendency II</span>"
    ]
  },
  {
    "objectID": "central2.html#harmonic-mean",
    "href": "central2.html#harmonic-mean",
    "title": "5  Central tendency II",
    "section": "5.2 Harmonic mean",
    "text": "5.2 Harmonic mean\nHarmonic means are often used in averaging things like rates (e.g. the average travel speed given duration of several trips). Harmonic mean (HM) of a set of observations is defined as the reciprocal of the arithmetic average of the reciprocal of the given value.\n\n\n\n\n\n\nNote\n\n\n\nHarmonic mean can be easily remembered as “reciprocal of the mean of the reciprocals”\n\n\nIf \\(x_{1},\\ x_{2},\\ldots,\\ x_{n}\\) are n observations then\n\\[\\mathbf{\\text{H.M}} = \\frac{n}{\\sum_{i = 1}^{n}\\frac{1}{x_{i}}} \\tag{5.5}\\]\nSteps in calculating Harmonic Mean (H.M)\n\nCalculate the reciprocal (1/value) for every value.\nFind the average of those reciprocals (just add them and divide by how many there are)\nThen do the reciprocal of that average (=1/average)\n\nExample 5.4 From the given data 5, 10, 17, 24, 30 calculate H.M\nSolution 5.4\nHere n = 5\n\n\n\nTable 5.4: Inverse of numbers to calculate harmonic mean\n\n\n\n\n\nx\n1/x\n\n\n\n\n5\n0.2\n\n\n10\n0.1\n\n\n17\n0.059\n\n\n24\n0.042\n\n\n30\n0.033\n\n\nTotal\n0.434\n\n\n\n\n\n\nusing Equation 5.5\n\\[HM=\\frac{5}{0.434} = 11.525\\]\n\n5.2.1 Harmonic mean for frequency table\n\\[\\mathbf{\\text{H.M}} = \\frac{n}{\\sum_{i = 1}^{k}{f_{i}\\frac{1}{x_{i}}}} \\tag{5.6}\\]\nwhere, \\(x_{i}\\) is the ith value in the dataset and for a grouped frequency table \\(x_{i}\\) will be the midpoint of the ith class interval calculated as the average of upper and lower limit, \\(f_{i}\\) is the frequency of the ith value or class , k is the number of classes.\nExample 5.5 For the given data calculate the harmonic mean.\n\n\n\nTable 5.5: Model data for harmonic mean calculation\n\n\n\n\n\nx\n20\n21\n22\n23\n24\n25\n\n\nfrequency (f)\n4\n2\n7\n1\n3\n1\n\n\n\n\n\n\nSolution 5.5\n\n\n\nTable 5.6: Calculation of harmonic mean from frequency table\n\n\n\n\n\nx\nf\n1/x\nf . (1/x)\n\n\n\n\n20\n4\n0.050\n0.200\n\n\n21\n2\n0.048\n0.095\n\n\n22\n7\n0.045\n0.318\n\n\n23\n1\n0.043\n0.043\n\n\n24\n3\n0.042\n0.125\n\n\n25\n1\n0.040\n0.04\n\n\n\n18\n\n0.822\n\n\n\n\n\n\nHere n =18\nusing Equation 5.6\n\\[HM = \\frac{18}{0.822} = 21.90\\]\nExample 5.6 Cistern Problem-Two pipes are used to fill a cistern. Pipe A can fill the cistern in 3 hours. Pipe B can fill the cistern in 5 hours. If both pipes are opened at the same time, how long will it take to fill the cistern completely?\nSolution 5.6\nTo solve the cistern problem, we first calculate the rate at which each pipe fills the cistern. Pipe A fills the cistern in 3 hours, so its rate is \\(\\frac{1}{3}\\) of the cistern per hour. Pipe B fills the cistern in 5 hours, so its rate is \\(\\frac{1}{5}\\) per hour. To find the combined rate, we add these rates together; \\(\\frac{1}{3} + \\frac{1}{5} = \\frac{8}{15}\\). This means the two pipes together fill \\(\\frac{8}{15}\\) of the cistern each hour. To find the total time, we take the reciprocal of the combined rate i.e. \\(\\text{Total time} = \\frac{1}{\\frac{8}{15}} = \\frac{15}{8} = 1.875\\). To convert 1.875 hours into hours and minutes, we first separate the whole number from the decimal part. 1.875 hours consists of 1 hour (the whole number) and 0.875 hours (the decimal part). Next, we convert the decimal part into minutes. Since 1 hour is equal to 60 minutes, we multiply 0.875 by 60 i.e. \\(0.875 \\times 60 = 52.5 \\, \\text{minutes}\\). Rounding 52.5 minutes gives approximately 53 minutes. Thus, 1.875 hours is equivalent to 1 hour and 53 minutes.\n\nThe problem can be easily solved using the harmonic mean, the harmonic mean of two pipes is\n\\[\nHM=\\frac{2}{\\frac{1}{3} +\\frac{1}{5}}\n\\]\n\\[= \\frac{2 \\cdot 3 \\cdot 5}{3 + 5} = \\frac{30}{8} = 3.75 \\, \\text{hours}\\]\nthe harmonic mean of the pipes is 3.75 hours, and since both pipes are working together, the total time is half of that, which confirms the answer of 1 hour and 53 minutes.\nExample 5.7 A car travels a certain distance from City A to City B at a speed of 60 km/h, and returns the same distance from City B to City A at a speed of 90 km/h. What is the average speed for the entire trip?\nSolution 5.7\nTo find the average speed when traveling the same distance at two different speeds, we use the harmonic mean. The harmonic mean for the speed is \\(\\frac{2 \\cdot S_1 \\cdot S_2}{S_1 + S_2}\\), where \\(S_1 = 60 \\, \\text{km/h}\\) is the speed from City A to City B, \\(S_2 = 90 \\, \\text{km/h}\\) is the speed from City B to City A.\nIn this case, we are calculating the average speed over the entire round trip. The harmonic mean is used because it accounts for the fact that traveling at different speeds over the same distance results in an overall average speed that is closer to the lower of the two speeds, rather than simply averaging the two speeds.\nNow, applying the harmonic mean formula:\n\\(S_{\\text{avg}} = \\frac{2 \\cdot 60 \\cdot 90}{60 + 90} = \\frac{10800}{150} = 72 \\, \\text{km/h}\\)\nSo, the average speed for the entire trip is 72 km/h.\nMerits and demerits of harmonic mean\nMerits\n\nIt is rigidly defined.\nIt is defined on all observations.\nIt is amenable to further algebraic treatment.\nIt is the most suitable average when it is desired to give greater weight to smaller and less weight to the larger ones.\n\nDemerits\n\nIt is not easily understood.\nIt is difficult to compute.\nIt is only a summary figure and may not be the actual item in the series.\nIt gives greater importance to small items and is therefore, useful only when small items have to be given greater weightage.\nIt is rarely used in grouped data.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Central tendency II</span>"
    ]
  },
  {
    "objectID": "central2.html#am-gm-or-hm",
    "href": "central2.html#am-gm-or-hm",
    "title": "5  Central tendency II",
    "section": "5.3 AM, GM or HM ?",
    "text": "5.3 AM, GM or HM ?\nThe arithmetic mean (AM), geometric mean (GM), and harmonic mean (HM) are termed as Pythagorean means. The Pythagorean means refer to three specific types of means that were known to the ancient Greek mathematicians, particularly to Pythagoras and his followers. Choosing the right average depends on what you’re measuring and how the data behaves. Let’s break it down step by step in a simple way:\nArithmetic Mean (AM)\nThe arithmetic mean is the most common type of average. You use it when the values in your data add together in a straightforward way. This is suitable for quantities like:\n- Heights or weights\n- Lengths or distances\n- Marks in exams\nFor example, if you want to find the average height of students in a class, you add up all the heights and divide by the number of students. The arithmetic mean gives a meaningful average because height or weight adds linearly.\nHarmonic Mean (HM)\nThe harmonic mean is useful when you are working with rates, ratios, or situations where quantities add up as reciprocals. Some examples include:\n- Speeds (distance per unit time)\n- Capacitors in a series circuit\n- Rates like fuel efficiency or cost per unit\nFor instance, imagine you are driving the same distance at different speeds. If you want to find the average speed for the entire trip, the harmonic mean is the best choice. This is because speeds relate inversely to time when you go faster, you take less time, and vice versa.\nGeometric Mean (GM)\nThe geometric mean is the right choice when your data involves multiplication or compounding, such as:\n- Growth rates (like population growth or interest rates)\n- Percentages (like inflation rates)\n- Ratios\nFor example, if you have annual interest rates for 10 years and want to find a single rate that represents the same total growth over that period, the geometric mean gives you the answer. It works by multiplying the rates and taking the root, which accounts for the compounding effect.\nHere’s a simple example to understand how the geometric mean works. Suppose you invest Rs.100, and your investment changes over three years as follows: in the first year, it grows by 10%, represented by a growth factor of 1.10; in the second year, it grows by 20%, represented by 1.20; and in the third year, it drops by 10%, represented by 0.90. To find a single rate that would give the same overall growth over the three years, you multiply the growth factors: \\(1.10 \\times 1.20 \\times 0.90 = 1.188\\). Then, take the cube root (since there are three years): \\(\\sqrt[3]{1.188} \\approx 1.059\\). This gives a geometric mean rate of approximately 1.059, or 5.9% per year. In other words, if your Rs. 100 investment grew steadily at a rate of 5.9% each year, it would result in the same total growth over three years, leaving you with about Rs. 118.80 at the end.\nKey Takeaways\n1. Use Arithmetic Mean when values combine directly, like adding lengths or weights.\n2. Use Harmonic Mean for rates or quantities that work reciprocally, like speed or resistance.\n3. Use Geometric Mean for data involving multiplication or compounding, like growth rates or percentages.\nBy understanding the relationship between the data and the type of average, you can choose the most meaningful measure for your analysis.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Central tendency II</span>"
    ]
  },
  {
    "objectID": "central2.html#relation-between-am-gm-and-hm",
    "href": "central2.html#relation-between-am-gm-and-hm",
    "title": "5  Central tendency II",
    "section": "5.4 Relation between AM, GM and HM",
    "text": "5.4 Relation between AM, GM and HM\nThe formula for the relation between AM, GM, HM is the product of arithmetic mean and harmonic mean is equal to the square of the geometric mean. This can be presented here in the form of Equation 5.7\n\\[\\mathbf{\\text{AM}}\\mathbf{\\times}\\mathbf{\\text{HM}}\\mathbf{=}\\mathbf{\\text{GM}}^{\\mathbf{2}} \\tag{5.7}\\]\nalso\n\\[\\mathbf{AM \\geq GM \\geq HM} \\tag{5.8}\\]\n\n5.4.1 Geometric illustration\nConsider two numbers a and b. See Figure 5.1 a semi circle can be drawn with diameter a+b. Then its radius is half the diameter, which will be the arithmetic mean \\(\\frac{a+b}{2}\\).\n\n\n\n\n\n\nFigure 5.1: Arithmetic mean on a semi circle\n\n\n\nThe geometric mean is the length of the perpendicular where a and b meet, which is never larger than the radius of the circle as illustrated in Figure 5.2\n\n\n\n\n\n\nFigure 5.2: Geometric mean on a semi circle\n\n\n\nNow draw a line from the top of red line which is the GM in Figure 5.2 to the center of the circle. Now that line is the radius of the circle, so it is equal to AM, which is now the hypotenuse of the newly formed triangle with GM as the leg of the triangle. So from Figure 5.3 it is clear that\n\\[\\mathbf{AM \\geq GM} \\tag{5.9}\\]\n\n\n\n\n\n\nFigure 5.3: Geometric mean and aritmetic mean on a semi circle\n\n\n\nNow if we draw an altitude to the hypotenuse as shown in Figure 5.3, the upper length on the hypotenuse is the harmonic mean . We can now consider another triangle where HM is a leg and the GM is the hypotenuse, this shows the GM is never smaller than the HM. So \\[\\mathbf{GM \\geq HM} \\tag{5.10}\\]\n\n\n\n\n\n\nFigure 5.4: AM, GM and HM on a semi circle\n\n\n\nNow from Equation 5.9 and Equation 5.10 it is clear that \\(\\mathbf{AM \\geq GM \\geq HM}\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Central tendency II</span>"
    ]
  },
  {
    "objectID": "central2.html#sec-positional_avg",
    "href": "central2.html#sec-positional_avg",
    "title": "5  Central tendency II",
    "section": "5.5 Positional averages",
    "text": "5.5 Positional averages\nPositional averages are measures derived directly from the values in a dataset. These averages are based on the position of the values within the series and are used to represent the overall dataset or highlight specific positional characteristics.\n\n\n\n\n\n\nNote\n\n\n\nThe median although a simple average is also a positional average that represents the middle value of an ordered dataset, making it a central point of reference. Similarly, the mode, which identifies the most frequently occurring value in the dataset, is also a positional average since it is directly taken from the series.\n\n\nThe other common positional averages include percentiles, quartiles, and deciles, which divide the data into equal parts to analyze its distribution.\nIn contrast, measures like the arithmetic mean, geometric mean, and harmonic mean are referred to as mathematical averages, as they are calculated through specific mathematical operations rather than being derived from the data’s positional properties.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Central tendency II</span>"
    ]
  },
  {
    "objectID": "central2.html#sec-quartile",
    "href": "central2.html#sec-quartile",
    "title": "5  Central tendency II",
    "section": "5.6 Quartiles",
    "text": "5.6 Quartiles\nThe median divides a dataset into two equal halves. Similarly, it is possible to divide a dataset into more than two parts. When an ordered dataset is divided into four equal sections, the points that mark these divisions are called quartiles.\nThe first or lower quartile (\\(\\mathbf{Q}_{\\mathbf{1}}\\)) is a value that has one fourth, or 25% of the observations below its value.\nThe second quartile (\\(\\mathbf{Q}_{\\mathbf{2}}\\)), has one-half, or 50% of the observations below its value. The second quartile is equal to the median.\nThe third or upper quartile, (\\(\\mathbf{Q}_{\\mathbf{3}}\\)), is a value that has three-fourths, or 75% of the observations below it. If there are n items in a dataset then\n\\[Q_1 = \\left( \\frac{n + 1}{4} \\right)^{\\text{th}} {\\text{item}} \\tag{5.11}\\]\n\\[Q_3 = \\left( \\frac{3(n + 1)}{4} \\right)^{\\text{th}} {\\text{item}} \\tag{5.12}\\]\nCalculations of quartiles are explained using the example below. See in the example the procedure followed when a fraction appear in the calculation.\nExample 5.8 Compute quartiles for the data 25, 18, 30, 8, 15, 5, 10, 35, 40, 45\nSolution 5.8\nFirst arrange the data in ascending order\n5, 8, 10, 15, 18, 25, 30, 35, 40, 45\nhere n = 10\nusing Equation 5.11 and Equation 5.12\n\\(Q_{1} = \\left( \\frac{10 + 1}{4} \\right)^{th}\\) = 2.75th item; when such a fraction appears we use the following procedure\n\\(Q_{1} =\\)2.75th item = 2nd item + 0.75(3rd item - 2nd item)\nSo from the given data \\(Q_{1}\\)= 8+0.75(10– 8) = 9.5, also \\(Q_{2}\\) is the median, here \\(Q_{2} =\\)(18+25)/2 = 21.5\n\\(Q_{3} = \\left(\\frac{3(10 + 1)}{4} \\right)^{th}\\) = 8.25th item = 8th item + 0.25(9th item - 8th item) = 35+0.25(40-35) = 36.25\nQuartiles of a discrete frequency data\nBelow it is explained steps in calculating quartiles for a discrete frequency data\n\nFind cumulative frequencies.\nFind \\(\\left( \\frac{n + 1}{4} \\right)\\)\nSee in the cumulative frequencies, the value just greater than \\(\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)\\), then the corresponding value of \\(x\\) is \\(Q_{1}\\)\nFind \\(\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)\\)\nSee in the cumulative frequencies, the value just greater than \\(\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)\\), then the corresponding value of \\(x\\) is \\(Q_{3}\\)\n\nExample 5.9 Compute quartiles for the data given below\n\n\n\nTable 5.7: A model frequency distribution\n\n\n\n\n\nx\n5\n8\n12\n15\n19\n24\n30\n\n\nf\n4\n3\n2\n4\n5\n2\n4\n\n\n\n\n\n\nSolution 5.9\n\n\n\nTable 5.8: Cumulative frequency data for quartile calculation\n\n\n\n\n\nx\nf\ncf\n\n\n\n\n5\n4\n4\n\n\n8\n3\n7\n\n\n12\n2\n9\n\n\n15\n4\n13\n\n\n19\n5\n18\n\n\n24\n2\n20\n\n\n30\n4\n24\n\n\n\n\n\n\nHere n =24\n\\(\\left( \\frac{n + 1}{4} \\right)\\) = \\(\\left( \\frac{25}{4} \\right)\\) = 6.25\nThe cumulative frequency value just greater than 6.25 is 7, the\n\\({x}\\) value corresponding to cumulative frequency 7 is 8. So \\({Q}_{1}\\) = 8\n\\(\\left( \\frac{3(n + 1)}{4} \\right)\\) = \\(\\left( \\frac{3 \\times 25}{4} \\right)\\) = 18.75\nThe cumulative frequency value just greater than 18.75 is 20, the\n\\(\\mathbf{x}\\) value corresponding to cumulative frequency 20 is 24. So \\({Q}_{3}\\) = 24\nQuartiles of a grouped frequency data\nBelow it is explained steps in calculating quartiles for a continuous frequency data\n\nFind cumulative frequencies\nFind \\(\\left( \\frac{n}{4} \\right)\\)\nSee in the cumulative frequencies, the value just greater than\\(\\left( \\frac{n}{4} \\right)\\), and then the corresponding class interval is called first quartile class.\nFind \\(3\\left( \\frac{n}{4} \\right)\\)\nSee in the cumulative frequencies the value just greater than \\(33\\left( \\frac{n}{4} \\right)\\)then the corresponding class interval is called 3rd quartile class. Then apply the respective formulae\n\n\\[Q_1 = l_1 + \\frac{\\frac{n}{4} - m_1}{f_1} \\times c_1 \\tag{5.13}\\]\n\\[Q_3 = l_3 + \\frac{3 \\left( \\frac{n}{4} \\right) - m_3}{f_3} \\times c_3 \\tag{5.14}\\]\nWhere, \\(l_{1}\\) = lower limit of the first quartile class\n\\(f_{1}\\) = frequency of the first quartile class\n\\(c_{1}\\) = width of the first quartile class\n\\(m_{1}\\) = cumulative frequency preceding the first quartile class\n\\(l_{3}\\)= 1ower limit of the 3rd quartile class\n\\(f_{3}\\)= frequency of the 3rd quartile class\n\\(c_{3}\\)= width of the 3rd quartile class\n\\(m_{3}\\) = cumulative frequency preceding the 3rd quartile class\nExample 5.10 Find the quartiles for the grouped frequency data given\n\n\n\nTable 5.9: A model grouped frequency data\n\n\n\n\n\nClass\nfrequency\ncumulative frequency\n\n\n\n\n0–10\n11\n11\n\n\n10–20\n18\n29\n\n\n20–30\n25\n54\n\n\n30–40\n28\n82\n\n\n40–50\n30\n112\n\n\n50–60\n33\n145\n\n\n60–70\n22\n167\n\n\n70–80\n15\n182\n\n\n80–90\n12\n194\n\n\n90–100\n10\n204\n\n\n\n\n\n\nSolution 5.10\n\\(\\left( \\frac{n}{4} \\right)\\) = \\(\\frac{204}{4}\\) = 51\nThe cumulative frequency value just greater than 51 is 54 so the class 20-30 is the 1st quartile class\nusing Equation 5.13\n\\[Q_1 = 20 + \\frac{51 - 29}{25} \\times 10 = 28.8\\]\n\\(3\\left( \\frac{n}{4} \\right)\\)= \\(3 \\times \\frac{204}{4}\\) = 153\nThe cumulative frequency value just greater than 153 is 167 so the class 60-70 is the 3rd quartile class\nusing Equation 5.14\n\\[Q_1 = 60 + \\frac{153 - 145}{22} \\times 10 = 63.63\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Central tendency II</span>"
    ]
  },
  {
    "objectID": "central2.html#percentiles",
    "href": "central2.html#percentiles",
    "title": "5  Central tendency II",
    "section": "5.7 Percentiles",
    "text": "5.7 Percentiles\nPercentiles divide an ordered dataset into 100 equal parts, with each part containing 1% of the observations. The pth percentile, denoted as \\(P_p\\), is the value below which x percent of the data falls.\nFor example:\n- The \\(\\mathbf{P}_{\\mathbf{50}}\\), 50th percentile is equivalent to the median, representing the middle value of the dataset.\n- The \\(\\mathbf{P}_{\\mathbf{25}}\\), 25th percentile corresponds to the first quartile (\\(Q_1\\)), which marks the lower 25% of the data.\n- The \\(\\mathbf{P}_{\\mathbf{75}}\\), 75th percentile is the third quartile (\\(Q_3\\)), indicating that 75% of the data falls below this value.\nFor raw data, first arrange the n observations in increasing order. Then the xth percentile is given by\n\\[P_p = \\left( \\frac{p(n + 1)}{100} \\right)^{\\text{th}} \\text{ item} \\tag{5.15}\\]\nPercentiles of discrete frequency data\nTo calculate percentiles for discrete frequency data, follow these steps which is similar to that of quartiles:\n\nFind the cumulative frequencies\nFind the position of the percentile. For the \\(p\\)-th percentile, calculate the position using the formula: \\[\nP_p = \\left( \\frac{p(n + 1)}{100} \\right)\n\\] where \\(p\\) is the percentile and \\(n\\) is the total number of data points.\nIdentify the value in the cumulative frequencies\n\nfind the cumulative frequency that is just greater than or equal to the calculated position \\(P_p\\). The corresponding value of \\(x\\) is the \\(p\\)-th percentile.\nFor example, to find the first percentile (\\(P_1\\)): - Calculate \\(P_1 = \\left( \\frac{1(n + 1)}{100} \\right)\\). - Locate the cumulative frequency that is just greater than \\(P_1\\), and the corresponding value of \\(x\\) is \\(P_1\\).\nPercentiles of a grouped frequency data\nCalculation of percentile is very much similar to that of quartile. For a frequency distribution the pth percentile is given by following steps\n\nFind cumulative frequencies\nFind \\(\\left( \\frac{p.n}{100} \\right)\\)\nSee in the cumulative frequencies, the value just greater than \\(\\left( \\frac{p.n}{100} \\right)\\) and then the corresponding class interval is called Percentile class.\nUse the following formula\n\n\\[P_p = l + \\frac{\\left( \\frac{p \\times n}{100} \\right) - cf}{f} \\times c \\tag{5.16}\\]\nWhere\n\\({l}\\) = lower limit of the percentile class\n\\({cf}\\) = cumulative frequency preceding the percentile class\n\\({f}\\) = frequency of the percentile class\n\\({c}\\) = class interval\n\\({n}\\) = total number of observations\nExample 5.11 Compute \\({P}_{25}\\) and \\({P}_{75}\\) for the data 25, 18, 30, 8, 15, 5, 10, 35, 40, 45\nSolution 5.11\nFirst arrange the data in ascending order\n5, 8, 10, 15, 18, 25, 30, 35, 40, 45\nHere n =10\n\\(P_{25} = \\left( \\frac{25(10 + 1)}{100} \\right)^{\\text{th}}\\) = 2.75th item\n\\(P_{25} =\\)2.75th item = 2nd item + 0.75(3rd item – 2nd item)\nSo from the given data \\(P_{25}\\)= 8+0.75(10– 8) = 9.5\n\\(P_{75} = \\left( \\frac{75(10 + 1)}{100} \\right)^{\\text{th}}\\) = 8.25th item\ni.e. \\(P_{75} = \\left( 75 \\times \\frac{10 + 1}{100} \\right)^{th}\\) = 8.25th item = 8th item + 0.25(9th item –8th item) = 35+0.25(40-35) =36.25\n\n\n\n\n\n\nNote\n\n\n\nData in Example 5.11 is same as Example 5.8; it can be seen that \\(P_{25} = Q_{1}\\) & \\(P_{75} = Q_{3}\\) always\n\n\n\n\n\n\n\n\nTry yourself\nFind \\(P_{25}\\), \\(P_{50}\\) & \\(P_{75}\\) for Example 5.9 & 5.10; verify that \\(P_{50} = Q_{2}\\), \\(P_{25} = Q_{1}\\) & \\(P_{75} = Q_{3}\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Central tendency II</span>"
    ]
  },
  {
    "objectID": "central2.html#deciles",
    "href": "central2.html#deciles",
    "title": "5  Central tendency II",
    "section": "5.8 Deciles",
    "text": "5.8 Deciles\nDeciles consist of 9 points that divide an ordered dataset into ten equal parts. The d th decile is denoted as \\(D_d\\). It is important to note that the median is the 5th decile.\n\\[D_d = \\left( \\frac{d(n + 1)}{10} \\right)^{\\text{th}} \\text{ item} \\tag{5.17}\\]\nwhere, \\(d\\) is the decile number (e.g., \\(d = 1\\) for the first decile, \\(d = 9\\) for the ninth decile), and \\(n\\) is the total number of data points.\nDeciles of discrete frequency data\nTo calculate deciles for discrete frequency data, follow these steps which are similar to that of percentiles:\n\nFind the cumulative frequencies.\nFind the position of the decile.\nFor the \\(d\\)-th decile, calculate the position using the formula:\n\\[D_d = \\left( \\frac{d(n + 1)}{10} \\right)\\]\n\nIdentify the value in the cumulative frequencies.\nFind the cumulative frequency that is just greater than or equal to the calculated position \\(D_d\\). The corresponding value of \\(x\\) is the \\(d\\)-th decile.\n\nFor example, to find the first decile (\\(D_1\\)): - Calculate \\(D_1 = \\left( \\frac{1(n + 1)}{10} \\right)\\). - Locate the cumulative frequency that is just greater than \\(D_1\\), and the corresponding value of \\(x\\) is \\(D_1\\).\nDeciles of a grouped frequency data\nFor a frequency distribution the dth decile is given by following steps\n\nFind cumulative frequencies\nFind \\(\\left( \\frac{d.n}{10} \\right)\\)\nSee in the cumulative frequencies, the value just greater than\\(\\left( \\frac{d.n}{10} \\right)\\)and then the corresponding class interval is called decile class.\nUse the following formula\n\n\\[D_d = l + \\frac{\\left( \\frac{d \\times n}{10} \\right) - cf}{f} \\times c \\tag{5.18}\\]\nWhere\n\\(l\\) = lower limit of the decile class\n\\({cf}\\) = cumulative frequency preceding the decile class\n\\({f}\\) = frequency of the decile class\n\\({c}\\) = class interval\n\\({n}\\) = total number of observations\n\n\n\n\n\n\nTry yourself\nFind \\(\\text{D}_{5}\\) for Example 5.9, 5.10 & 5.11; verify that \\({D}_{5} = {Q}_{2} = {P}_{50} = median\\)\n\n\n\n\n\n\n\n\n\nHistorical Insights\n\n\n\nThe Harmonic mean and the perfect fourth\nThe harmonic mean a term derived from the ancient Greeks, particularly associated with Pythagoras or his followers. The harmonic mean is closely related to musical intervals, specifically the perfect fourth. In music theory, an octave change upwards corresponds to a doubling of the frequency (a 1:2 ratio). The harmonic mean of 1 and 2, which is \\(\\frac{4}{3}\\), defines the frequency ratio for the perfect fourth, making it a crucial concept in understanding musical harmony and acoustics.\n\n\n\n\n\n\n\n\nQuotes to Inspire\n\n\n\n“The best thing about being a statistician is that you get to play in everybody else’s backyard”. – John Tukey",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Central tendency II</span>"
    ]
  },
  {
    "objectID": "dispersion.html",
    "href": "dispersion.html",
    "title": "6  Measures of dispersion",
    "section": "",
    "text": "6.1 Characteristics of a good measure of dispersion\nIn the previous chapters, we have seen how a set of data can be summarized by a single representative value that describes the central tendency of the data. Consider the two sets of data, A and B, in Table 6.1.\nYou can see mean, median and mode for both the sets A & B in Table 6.1 is 3\nThe plot of values of A and B in Table 6.1 can be seen in Figure 6.1. The figure is known as dot plot.\nIt can be seen in Figure 6.1 that, while values of data set A are grouped close to their mean, while the values of data set B are more spread out. We say that values of data set B are more dispersed (or scattered) than those of data set A. This example shows that the measures of central tendency are not enough in describing a set of data. In addition to using these measures, we need numerical measures of dispersion (or variation) of a set of data.\nAn ideal measure of dispersion is expected to possess the following properties\nThe most important measures of dispersion are range, quartile deviation, variance, inter-quartile range, mean absolute deviation and standard deviation.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Measures of dispersion</span>"
    ]
  },
  {
    "objectID": "dispersion.html#characteristics-of-a-good-measure-of-dispersion",
    "href": "dispersion.html#characteristics-of-a-good-measure-of-dispersion",
    "title": "6  Measures of dispersion",
    "section": "",
    "text": "It should be rigidly defined.\nIt should be based on all the items.\nIt should not be unduly affected by extreme items.\nIt should lend itself for algebraic manipulation.\nIt should be simple to understand and easy to calculate.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Measures of dispersion</span>"
    ]
  },
  {
    "objectID": "dispersion.html#the-range",
    "href": "dispersion.html#the-range",
    "title": "6  Measures of dispersion",
    "section": "6.2 The range",
    "text": "6.2 The range\nThis is the simplest possible measure of dispersion. The range of a set of data is defined as the difference between the largest observation and the smallest observation in the set of data.\nThus,\nRange = largest observation – smallest observation.\nIt can be denoted as, Range = L – S.\nWhere L = Largest value; S = Smallest value.\nExample 6.1 The marks obtained by 8 students in mathematics and physics examinations are as follows:\n\n\n\nTable 6.2: Model dataset of marks obtained in two subjects\n\n\n\n\n\nStudent\nMathematics\nPhysics\n\n\n\n\n1\n35\n50\n\n\n2\n60\n55\n\n\n3\n70\n70\n\n\n4\n40\n65\n\n\n5\n85\n89\n\n\n6\n96\n68\n\n\n7\n55\n72\n\n\n8\n65\n80\n\n\n\n\n\n\nFind the ranges of the two sets of data. Are the physics marks more dispersed than the mathematics marks?\nSolution 6.1\nFor mathematics,\nHighest mark = 96, lowest mark = 35, range =96 – 35 = 61\nFor physics,\nHighest mark = 89, lowest mark = 50, range =89 – 50 = 39.\nThe mathematics marks have a wider range than the Physics marks. The Mathematics marks are therefore more dispersed than the Physics marks.\nIn individual observations and discrete series, L and S are easily identified. In case of grouped frequency distribution, the following method is employed.\nL = Upper boundary of the highest class\nS = Lower boundary of the lowest class.\n\\[Range = L - S \\tag{6.1}\\]\nExample 6.2: Calculate range from the following distribution\n\n\n\nTable 6.3: Model frequency distribution table for range calculation\n\n\n\n\n\nSize\n60–63\n63–66\n66–69\n69–72\n72–75\n\n\nNumber\n5\n18\n42\n27\n8\n\n\n\n\n\n\nSolution 6.2\nL = Upper boundary of the highest class = 75\nS = Lower boundary of the lowest class = 60\nRange = L – S = 75 – 60 = 15\nMerits and demerits of range\nMerits\n\nIt is simple to understand.\nIt is easy to calculate.\nIn certain types of problems like quality control, weather forecasts, share price analysis, etc.\n\nDemerits\n\nIt is very much affected by the extreme items.\nIt is based on only two extreme observations.\nIt cannot be calculated from open-end class intervals.\nIt is not suitable for mathematical treatment.\nIt is a very rarely used measure.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Measures of dispersion</span>"
    ]
  },
  {
    "objectID": "dispersion.html#the-inter-quartile-range-iqr",
    "href": "dispersion.html#the-inter-quartile-range-iqr",
    "title": "6  Measures of dispersion",
    "section": "6.3 The inter-quartile range (IQR)",
    "text": "6.3 The inter-quartile range (IQR)\nThe range is a simple and quick measure to calculate. However, because it relies solely on the maximum and minimum values in a data set, it does not provide information about how the data is distributed between these two values. As a result, the range may not be an effective measure of dispersion, especially if one or both of these values are significantly different from the rest of the data. To address this limitation, the interquartile range is often used. The interquartile range is a more robust measure of dispersion, defined as the difference between the upper and lower quartiles of the data. IQR is also known as midspread. Thus,\n\\[IQR = Q_3 - Q_1 \\tag{6.2}\\]\nThe inter-quartile range of a set of data is therefore not affected by values of the data outside Q1 and Q3 making it a more reliable measure of spread for skewed or non-normal distributions.\nExample 6.3 Consider the two sets of data A & B below, find IQR\n\n\n\nTable 6.4: Model dataset for IQR calculation\n\n\n\n\n\nA\n3\n4\n5\n6\n8\n9\n10\n12\n15\n\n\nB\n3\n8\n8\n9\n9\n9\n10\n10\n15\n\n\n\n\n\n\nFor data set A, Q1 = 4.5, Q3 = 11; so Inter-Quartile Range =11 – 4.5 = 6.5\nFor data set B, Q1 = 8, Q3 = 10; so Inter-Quartile Range =10 – 8 = 2\nSince the interquartile range (IQR) of data set A is greater than that of data set B, these results indicate that data set A is more dispersed than data set B. It is also noticeable that the range is the same for both sets.\nMerits and Demerits of IQR\nMerits\n\nIt is simple to calculate and easy to understand.\nIt is not affected by extreme values (outliers) in the data, making it a more reliable measure of spread than the range.\nIQR provides a clear measure of the spread of the middle 50% of the data, giving a better representation of variability when data is skewed.\nIt can be used for skewed distributions, where the range and standard deviation may not be as useful.\nIQR is particularly useful in identifying outliers, as data points outside 1.5 times the IQR from the quartiles are often considered outliers.\n\nDemerits\n\nThe IQR does not use all the data points, which means it may not represent the variability of the entire dataset.\nIt may not be as intuitive as the range or standard deviation for some users, particularly in more complex datasets.\nThe IQR is less sensitive to variations in the data outside of the interquartile range, meaning it might not fully reflect extreme values or trends.\nIt is not as effective when comparing datasets with significantly different shapes or distributions.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Measures of dispersion</span>"
    ]
  },
  {
    "objectID": "dispersion.html#mean-absolute-deviation-mad",
    "href": "dispersion.html#mean-absolute-deviation-mad",
    "title": "6  Measures of dispersion",
    "section": "6.4 Mean absolute deviation (MAD)",
    "text": "6.4 Mean absolute deviation (MAD)\nThe mean absolute deviation (MAD) is a measure of variability that indicates the average distance between observations and their mean. MAD uses the original units of the data, which simplifies interpretation. Larger values signify that the data points spread out further from the average. Conversely, lower values correspond to data points bunching closer to it. The mean absolute deviation is also known as the mean deviation and average absolute deviation.\nHere is how to calculate the mean absolute deviation.\n\nCalculate the mean.\nCalculate the difference of each observation from mean and take absolute value i.e. ignore the sign. This difference is known as absolute deviation\nAdd those deviations together.\nDivide the sum by the number of data points.\n\n\\[MAD = \\frac{\\sum_{i = 1}^{n}\\left| x_{i} - \\overline{x} \\right|}{n} \\tag{6.3}\\]\nExample 6.4 find the mean absolute deviation of the following 10, 15, 15, 17, 18, 21\n\n\n\nTable 6.5: Calculation of mean absolute deviation\n\n\n\n\n\n\n\n\n\n\n\\[x_{i}\\]\n\\[x_{i} - \\overline{x}\\]\n\\[\\left| x_{i} - \\overline{x}\\right|\\]\n\n\n\n\n10\n-6\n6\n\n\n15\n-1\n1\n\n\n15\n-1\n1\n\n\n17\n1\n1\n\n\n18\n2\n2\n\n\n21\n5\n5\n\n\n\\(\\overline{x} =\\) 16\n\n\\(\\sum_{i = 1}^{n}\\left| x_{i} - \\overline{x} \\right|\\) = 16\n\n\n\n\n\n\nHere n = 6 and \\(\\sum_{i = 1}^{n}\\left| x_{i} - \\overline{x} \\right|\\) = 16 therefore MAD = \\(\\frac{16}{6} = 2.67\\)\nMerits and demerits of MAD\nMerits\n\nMean deviation is simple and easy.\nDifferent items of observations can be easily compared with mean deviation.\nMean deviation is better than quartile deviation and range because it is based on all the observations of the series.\nMean deviation is less affected by the extreme values in the series while comparing to standard deviation.\nMean deviation is rigidly defined. So, it has fixed value.\nMean deviation about median will be least.\n\nDemerits\n\nMean deviation becomes difficult to compute mean deviation in case of fractions.\nIt is not applicable for algebraic calculations.\nIt cannot be calculated from open-end class intervals.\nMean deviation is not a good measure as it ignores negative signs of deviations.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Measures of dispersion</span>"
    ]
  },
  {
    "objectID": "dispersion.html#the-variance-and-standard-deviation",
    "href": "dispersion.html#the-variance-and-standard-deviation",
    "title": "6  Measures of dispersion",
    "section": "6.5 The variance and standard deviation",
    "text": "6.5 The variance and standard deviation\nThe most important measures of variability are the sample variance and the sample standard deviation. If x1, x2… xn is a sample of n observations, then the sample variance is denoted by s² and is defined by the equation.\n\\[\n\\mathbf{\\text{sample variance},\\ s}^{2} = \\frac{\\sum_{i = 1}^{n} (x_{i} - \\overline{x})^{2}}{n - 1}\n\\tag{6.4}\\]\nThe sample standard deviation, s, is the positive square root of the sample variance.\n\\[\\mathbf{\\text{standard deviation} ,\\ s = \\ }\\sqrt{\\frac{\\sum_{i = 1}^{n} (x_{i} - \\overline{x})^{2}}{n - 1}} \\tag{6.5}\\]\n\n\n\n\n\n\nNote\n\n\n\nWhy standard deviation?\nWhile both variance and standard deviation measure data dispersion, standard deviation is preferred for practical interpretation. Variance is expressed in squared units, making it harder to interpret. For example, if the data represents lengths in meters, the variance is in square meters (m²), which complicates understanding variability. In contrast, standard deviation is the square root of variance, preserving the original unit (e.g., meters), making it more intuitive. Thus, standard deviation is preferred for its clarity and ease of interpretation, especially when analyzing how data points deviate from the mean.\n\n\nIf the standard deviation of data set A is greater than that of data set B, it indicates that data set A is more dispersed than data set B. A higher standard deviation means that the values in data set A are more spread out from the mean compared to the values in data set B. It’s important to note that the standard deviation of any data set is always a non-negative number, as it represents the square root of the variance, which is always non-negative. Variance and standard deviation can never be negative values.\nExample 6.5 Consider the Table 6.1 discussed earlier, find the standard deviation?\nSolution 6.5\n\n\n\nTable 6.6: Calculation of standard deviation set A\n\n\n\n\n\n\n\n\n\n\n\nSet A\n\\[x_{i}\\]\n\\[x_{i} - \\overline{x}\\]\n\\[\n\\left( x_{i} - \\overline{x} \\right)^{2}\n\\]\n\n\n\n1\n-2\n4\n\n\n\n2\n-1\n1\n\n\n\n3\n0\n0\n\n\n\n3\n0\n0\n\n\n\n4\n1\n1\n\n\n\n5\n2\n4\n\n\nSum\n18\n0\n10\n\n\n\n\n\n\nMean (\\(\\overline{x}\\)) =\\(\\ \\frac{18}{6} = 3\\)\n\\[{sample\\ variance,\\ s}_{A}^{2} = \\frac{\\sum_{i = 1}^{n}\\left( x_{i} - \\overline{x} \\right)^{2}}{n - 1} = \\frac{10}{5} = 2\\]\n\\[\\text{sample standard deviation,}\\ s_{A} = \\ \\sqrt{s_{A}^{2}} = \\ \\sqrt{2} = 1.414\\]\n\n\n\nTable 6.7: Calculation of standard deviation set B\n\n\n\n\n\n\n\n\n\n\n\nSet B\n\\[x_{i}\\]\n\\[x_{i} - \\overline{x}\\]\n\\[\n\\left( x_{i} - \\overline{x} \\right)^{2}\n\\]\n\n\n\n-1\n-4\n16\n\n\n\n0\n-3\n9\n\n\n\n3\n0\n0\n\n\n\n3\n0\n0\n\n\n\n5\n2\n4\n\n\n\n8\n5\n25\n\n\nSum\n18\n0\n54\n\n\n\n\n\n\nMean (\\(\\overline{x}\\)) =\\(\\ \\frac{18}{6} = 3\\)\n\\[{Sample\\ variance,\\ s}_{B}^{2} = \\frac{\\sum_{i = 1}^{n}\\left( x_{i} - \\overline{x} \\right)^{2}}{n - 1} = \\frac{54}{5} = 10.8\\]\n\\[Sample\\ standard\\ deviation,\\ s_{B} = \\ \\sqrt{s_{B}^{2}} = \\ \\sqrt{10.8} = 3.29\\]\nIt can be seen that \\(s_{B} &gt; s_{A}\\), confirming that data set B is more dispersed than data set A as shown in Figure 6.1\nAn alternative formula for computing the variance\nThe computation of s² requires calculations of \\(\\overline{x}\\), n subtractions and n squaring and adding operations. If the original observations or the deviations \\(\\left( x_{i} - \\overline{x} \\right)\\) are not integers, the deviations \\(\\left( x_{i} - \\overline{x} \\right)\\) may be difficult to work with, and several decimals may have to be carried to ensure numerical accuracy. A more efficient computational formula for s² is given by\n\\[s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{i = 1}^{n}{x_{i}^{2} - \\frac{1}{n}}\\left( \\sum_{i = 1}^{n}x_{i} \\right)^{2} \\right\\} \\tag{6.6}\\]\nExample 6.6 Consider the data set below; find standard deviation?\n\n\n\nTable 6.8: Model dataset for standard deviation calculation\n\n\n\n\n\n3\n4\n5\n6\n8\n9\n10\n12\n15\n\n\n\n\n\n\nSolution 6.6\n\n\n\nTable 6.9: Calculation of sd using alternate formula\n\n\n\n\n\n\n\n\n\n\\[x_{i}\\]\n\\[x_{i}^{2}\\]\n\n\n\n\n3\n9\n\n\n4\n16\n\n\n5\n25\n\n\n6\n36\n\n\n8\n64\n\n\n9\n81\n\n\n10\n100\n\n\n12\n144\n\n\n15\n225\n\n\n\\(\\sum_{i=1}^{9} x_{i}\\) = 72\n\\(\\sum_{i=1}^{9} x_{i}^{2}\\) = 700\n\n\n\n\n\n\nusing Equation 6.6 ; here n = 9\n\\(s^{2} = \\frac{1}{8}\\left\\{ 700 - {\\frac{1}{9}\\left( 72 \\right)}^{2} \\right\\}\\) =15.5\n\\(s = \\ \\sqrt{15.5} = 3.94\\)\n\n6.5.1 Standard deviation for frequency table\nFor discrete frequency table\n\\[s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{i = 1}^{n}{{f_{i}x}_{i}^{2} - \\frac{1}{n}}\\left( \\sum_{i = 1}^{n}{f_{i}x}_{i} \\right)^{2} \\right\\} \\tag{6.7}\\]\nwhere \\(x_i\\) is the ith observation and \\(f_{i}\\) is the corresponding frequency\nExample 6.7 The frequency distributions of seed yield of 50 sesamum plants are given below. Find the standard deviation.\n\n\n\nTable 6.10: A model frequency distributions of seed yield\n\n\n\n\n\nSeed yield in gms (x)\n3\n4\n5\n6\n7\n\n\nFrequency (f)\n4\n6\n15\n15\n10\n\n\n\n\n\n\nSolution 6.7\n\n\n\nTable 6.11: Calculation of standard deviation for frequency table\n\n\n\n\n\nx\nf\nf.x\nf.x2\n\n\n3\n4\n12\n36\n\n\n4\n6\n24\n96\n\n\n5\n15\n75\n375\n\n\n6\n15\n90\n540\n\n\n7\n10\n70\n490\n\n\nTotal\n50\n271\n1537\n\n\n\n\n\n\nusing Equation 6.7\n\\[{sample\\ variance,\\ s}^{2} = \\frac{1}{50 - 1}\\left\\{ 1537 - \\frac{271^{2}}{50} \\right\\} = 1.3914\\]\n\\(standard\\ deviation,\\ s = \\sqrt{1.3914}\\) = 1.179\nFor grouped frequency table\n\\[s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{i = 1}^{n}{{f_{i}d}_{i}^{2} - \\frac{1}{n}}\\left( \\sum_{i = 1}^{n}{f_{i}d}_{i} \\right)^{2} \\right\\} \\tag{6.8}\\]\nwhere \\(f_{i}\\) is the frequency of ith class, \\(d_{i} = \\frac{x_{i} - A}{c}\\), where \\(x_{i}\\) is the class mark, \\(A\\) is the class mark with the highest frequency and c is the class interval\nExample 6.8 The frequency distributions of seed yield of 50 sesamum plants are given below. Find the standard deviation\n\n\n\nTable 6.12: A model gropued frequency distributions of seed yield\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeed yield in gms (x)\n2.5–3.5\n3.5–4.5\n4.5–5.5\n5.5–6.5\n6.5-7.5\n\n\nFrequency (f)\n4\n6\n15\n15\n10\n\n\n\n\n\n\nSolution 6.8\nHere n =50; c =1\n\n\n\nTable 6.13: Calculation of sd for grouped frequency distribution\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeed yield\nf\nx\n\\[d_{i} = \\frac{x_{i} - A}{c}\\]\nf.d\nf.d2\n\n\n\n\n2.5–3.5\n4\n3\n-2\n-8\n16\n\n\n3.5–4.5\n6\n4\n-1\n-6\n6\n\n\n4.5–5.5\n15\n5\n0\n0\n0\n\n\n5.5–6.5\n15\n6\n1\n15\n15\n\n\n6.5–7.5\n10\n7\n2\n20\n40\n\n\nTotal\n50\n25\n0\n21\n77\n\n\n\n\n\n\nA = 5\nusing Equation 6.8\n\\[{sample\\ variance,\\ s}^{2} = \\frac{1}{49}\\left( 77 - \\frac{\\left( 21 \\right)^{2}}{50} \\right) = \\ 1.3914\\]\n\\(standard\\ deviation,\\ s = \\sqrt{1.3914}\\) = 1.179\n\n\n6.5.2 Merits and demerits of standard deviation\nMerits\n\nIt is rigidly defined and its value is always definite and based on all the observations.\nAs it is based on arithmetic mean, it has all the merits of arithmetic mean.\nIt is the most important and widely used measure of dispersion.\nIt is possible for further algebraic treatment.\nIt is less affected by the fluctuations of sampling and hence stable.\nIt is the basis for measuring the coefficient of correlation and other measures.\n\nDemerits\n\nIt is not easy to understand and it is difficult to calculate.\nIt gives more weight to extreme values because the values are squared up.\nAs it is an absolute measure of variability, it cannot be used for the purpose of comparison.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Measures of dispersion</span>"
    ]
  },
  {
    "objectID": "dispersion.html#coefficient-of-variation",
    "href": "dispersion.html#coefficient-of-variation",
    "title": "6  Measures of dispersion",
    "section": "6.6 Coefficient of variation",
    "text": "6.6 Coefficient of variation\nThe standard deviation is an absolute measure of dispersion. It is expressed in terms of units in which the original figures are collected and stated. The standard deviation of heights of plants cannot be compared with the standard deviation of weights of the grains, as both are expressed in different units, i.e heights in centimetre and weights in kilograms.\nTherefore the standard deviation must be converted into a relative measure of dispersion for the purpose of comparison. The relative measure is known as the coefficient of variation. The coefficient of variation is obtained by dividing the standard deviation by the mean and expressed in percentage.\n\\[\\text{Coefficient of variation} \\, (C.V) = \\frac{\\text{standard deviation}}{\\text{mean}} \\times 100 \\tag{6.9}\\]\nA higher C.V. indicates greater variability in the dataset, meaning the data values are more dispersed relative to the mean. In contrast, a lower C.V. signifies lower variability, indicating that the data values are more closely clustered around the mean. This measure is particularly useful when comparing datasets with different units or scales.\nExample 6.9 Consider the measurement on yield and plant height of a paddy variety. The mean and standard deviation for yield are 50 kg and 10 kg respectively. The mean and standard deviation for plant height are 55 cm and 5 cm respectively. Compare the variability.\nSolution 6.9\nHere the measurements for yield and plant height are in different units. Hence the variability can be compared only by using coefficient of variation.\nFor yield, CV=\\(\\ \\frac{10}{50} \\times 100 =\\) 20%\nFor plant height, CV= \\(\\frac{5}{55} \\times 100 =\\) 9.1%\nThe yield is subject to more variation than the plant height.\n \n \n\n\n\n\n\n\n\nHistorical Insights\n\n\n\nExploring variability\nThe term “standard deviation” was first introduced in writing by Karl Pearson in 1894 in his paper “Contributions to the Mathematical Theory of Evolution.” Prior to this, the concept was referred to by other names, including “mean error,” “mean square error,” and “error of mean square,” reflecting its origins in the study of measurement errors and variability.(Pearson 1894)\nThe concept of variance was formalized in 1918 by Sir Ronald Aylmer Fisher in his seminal paper “The Correlation Between Relatives on the Supposition of Mendelian Inheritance.” While earlier mathematicians like Carl Friedrich Gauss made significant contributions to the development of probability and error theory, which influenced the understanding of variability, the term “variance” as we know it today was introduced by Fisher.(Fisher 1918)\n\n\n\n\n\n\n\n\nQuotes to Inspire\n\n\n\n“The object of our being statistical is to learn how to improve the whole health of humanity” – Florence nightingale\n\n\n\n\n\n\n\nFisher, Ronald A. 1918. “The Correlation Between Relatives on the Supposition of Mendelian Inheritance.” Transactions of the Royal Society of Edinburgh 52 (2): 399–433. https://doi.org/10.1017/S0080456800012163.\n\n\nPearson, Karl. 1894. “Contributions to the Mathematical Theory of Evolution.” Philosophical Transactions of the Royal Society of London. A 185: 71–110. https://doi.org/10.1098/rsta.1894.0003.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Measures of dispersion</span>"
    ]
  },
  {
    "objectID": "skewness.html",
    "href": "skewness.html",
    "title": "7  Skewness and kurtosis",
    "section": "",
    "text": "7.1 Skewness\nIn the previous chapter, we explored numerical measures of central tendency and dispersion. Together, these measures give us insights into the location and spread of our data. However, they don’t fully describe the data distribution. What about its shape?\nThe shape of a distribution helps us understand the symmetry, peakedness, and presence of tails in the data. While a histogram provides a visual summary of the shape, we often need numerical measures for precise analysis. These measures include:\nIn this chapter, we will have a detailed discussion on these two important measures of shape, understanding how they are calculated and interpreted. By the end, you’ll be able to evaluate whether a distribution is symmetric, positively or negatively skewed, and whether it has light or heavy tails.\nSkewness is a measure of symmetry, or more precisely, the lack of symmetry. Then you may ask, what will a symmetric distribution looks like. Histogram of a symmetric distribution is showed in Figure 7.1.\nA distribution, or data set, is symmetric if it looks the same to the left and right of the centre point. In our discussion we are including only unimodal cases.\nFigure 7.3 shows a model data set with skewness = 0 (symmetric distribution)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Skewness and kurtosis</span>"
    ]
  },
  {
    "objectID": "skewness.html#skewness",
    "href": "skewness.html#skewness",
    "title": "7  Skewness and kurtosis",
    "section": "",
    "text": "Figure 7.1: Histogram of a symmetric distribution\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor a symmetric distribution skewness = 0; mean = median = mode. Figure 7.2 shows how a symmetric distribution looks like.\n\n\n\n\n\n\n\n\nFigure 7.2: symmetric distribution\n\n\n\n\n\n\n\n\n\n\nFigure 7.3: Data set with skewness = 0\n\n\n\n\n7.1.1 Negatively skewed\nA negatively skewed distribution, also known as a left-skewed distribution, is characterized by a longer tail on the left side of the distribution. The bulk of the data values, or the “mass” of the distribution, is concentrated on the right, as shown in Figure 7.4.\nThis type of distribution is referred to as left-skewed, left-tailed, or skewed to the left because of the extended left tail. In such cases, the numerical relationship between the mean, median, and mode typically follows this pattern:\nMean &lt; Median &lt; Mode\nThis occurs because the mean is pulled towards the longer tail, while the median and mode remain closer to the center of the data’s bulk.\n\n\n\n\n\n\nFigure 7.4: Left skewed or negatively skewed distribution\n\n\n\nFigure 7.5 shows a model dataset with negative skewness.\n\n\n\n\n\n\nFigure 7.5: Negatively skewed data set\n\n\n\n\n\n7.1.2 Positively skewed\nA positively skewed distribution, also known as a right-skewed distribution, is characterized by a longer tail on the right side. The bulk of the data values, or the “mass” of the distribution, is concentrated on the left, as illustrated in Figure 7.6.\nThis type of distribution is referred to as right-skewed, right-tailed, or skewed to the right, due to the extended tail on the right. In such cases, the relationship between the mean, median, and mode typically follows this pattern:\nMean &gt; Median &gt; Mode\nThis occurs because the mean is influenced by the extreme values in the longer right tail, while the median and mode remain closer to the center of the data’s bulk.\n\n\n\n\n\n\nFigure 7.6: Right skewed or positively skewed distribution\n\n\n\nFigure 7.7 shows a model dataset with positive skewness.\n\n\n\n\n\n\nFigure 7.7: Data set with positive skewness or right skewed",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Skewness and kurtosis</span>"
    ]
  },
  {
    "objectID": "skewness.html#measures-of-skewness",
    "href": "skewness.html#measures-of-skewness",
    "title": "7  Skewness and kurtosis",
    "section": "7.2 Measures of skewness",
    "text": "7.2 Measures of skewness\nThe direction and extent of skewness can be measured in various ways. We shall discuss four measures.\n\n7.2.1 Karl Pearson’s coefficient of skewness (\\(S_{k}\\))\nYou have noticed that the mean, median and mode are not equal in a skewed distribution. The Karl Pearson’s measure of skewness is based upon the divergence of mean from mode in a skewed distribution.\n\\[S_{k} = \\frac{mean - mode}{\\text{standard deviation}} \\tag{7.1}\\]\nThe sign of \\(S_{k}\\) gives the direction of skewness and its magnitude gives the extent of skewness. If \\(S_{k}\\) &gt; 0, the distribution is positively skewed, and if \\(S_{k}\\) &lt; 0 it is negatively skewed.\nIn Equation 7.1 since mode is used, there is a problem that if mode is not defined for a distribution we cannot find \\(S_{k}\\). But empirical relation between mean, median and mode states that, for a moderately symmetrical distribution \\(\\ mean - mode \\approx 3(mean - median)\\). So Equation 7.1 can be written as\n\\[S_{k} = \\frac{3(mean - median)}{\\text{standard deviation}} \\tag{7.2}\\]\nExample 7.1 Compute the Karl Pearson’s coefficient of skewness from the following data:\n\n\n\nTable 7.1: Model dataset for skewness calculation\n\n\n\n\n\nHeight (x)\nfrequency (f)\n\n\n\n\n58\n10\n\n\n59\n18\n\n\n60\n30\n\n\n61\n42\n\n\n62\n35\n\n\n63\n28\n\n\n64\n16\n\n\n65\n8\n\n\n\n\n\n\nSolution 7.1\n\n\n\nTable 7.2: Karl Pearson’s coefficient of skewness\n\n\n\n\n\n\nHeight (\\(x_{i}\\))\n\n\nfrequency (\\(f_{i}\\))\n\n\n\\(f_{i}x_{i}\\)\n\n\n\\(f_{i}x_{i}^{2}\\)\n\n\n\n\n\n\n58\n\n\n10\n\n\n580\n\n\n33640\n\n\n\n\n59\n\n\n18\n\n\n1062\n\n\n62658\n\n\n\n\n60\n\n\n30\n\n\n1800\n\n\n108000\n\n\n\n\n61\n\n\n42\n\n\n2562\n\n\n156282\n\n\n\n\n62\n\n\n35\n\n\n2170\n\n\n134540\n\n\n\n\n63\n\n\n28\n\n\n1764\n\n\n111132\n\n\n\n\n64\n\n\n16\n\n\n1024\n\n\n65536\n\n\n\n\n65\n\n\n8\n\n\n520\n\n\n33800\n\n\n\n\nSum\n\n\n187\n\n\n11482\n\n\n705588\n\n\n\n\n\n\n\nMean, \\(\\overline{x} = \\frac{\\sum_{i = 1}^{n}{f_{i}x_{i}}}{\\sum_{i = 1}^{n}f_{i}}\\) = \\(\\frac{11482}{187} = 61.40\\)\n\\({sample\\ variance,\\ s}^{2}\\) using Equation 6.7 = \\(\\frac{705588 - \\frac{\\left( 11482 \\right)^{2}}{187}}{186} = 3.123\\)\n\\(standard\\ deviation,\\ s = \\sqrt{3.123} = 1.76\\)\nTo calculate the median, refer to the table Table 7.3. Locate the cumulative frequency just greater than \\(\\frac{n + 1}{2}\\), and the corresponding value of \\(x\\) will be the median (\\(Q_2\\)).\nHere, \\(\\frac{n + 1}{2} = \\frac{187 + 1}{2} = \\frac{188}{2} = 94\\).\nFrom the table Table 7.3, it is evident that the median is 61.\n\n\n\nTable 7.3: Cumulative frequency for skewness calculation\n\n\n\n\n\nHeight (x)\nfrequency (f)\ncumulative frequency\n\n\n\n\n58\n10\n10\n\n\n59\n18\n28\n\n\n60\n30\n58\n\n\n61\n42\n100\n\n\n62\n35\n135\n\n\n63\n28\n163\n\n\n64\n16\n179\n\n\n65\n8\n187\n\n\n\n\n\n\nusing Equation 7.2\n\\[S_{k} = \\frac{3(61.40 - 61)}{1.76} = \\frac{1.2}{1.76} = 0.68\\]\nHence, the Karl Pearson’s coefficient of skewness \\(S_{k}\\)=\\(0.68\\), Thus the distribution is positively skewed.\n\n\n7.2.2 Bowley’s measure of skewness (SQ)\nKarl Pearson’s coefficient of skewness is most commonly used skewness measure. However, in order to use it you must know the mean, mode (or median) and standard deviation for your data. Sometimes you might not have that information; instead you might have information about quartiles. If that’s the case, you can use Bowley’s measure of skewness as an alternative to find out more about the asymmetry of your distribution. It’s very useful if you have extreme data values (outliers) or if you have an open-ended distribution.\n\\[{Bowley’s\\ measure\\ of\\ Skewness,\\ S}_{Q} = \\frac{\\left( Q_{3} - Q_{2} \\right) - \\left( Q_{2} - Q_{1} \\right)}{\\left( Q_{3} - Q_{2} \\right) + \\left( Q_{2} - Q_{1} \\right)} \\tag{7.3}\\]\nWhere \\(Q_{1}\\)= 1st quartile; \\(Q_{2}\\) = median; \\(Q_{3}\\)= 3rd quartile\nEquation can be further modified into\n\\[S_{Q} = \\frac{Q_{3} - 2Q_{2} + Q_{1}}{Q_{3} - Q_{1}} \\tag{7.4}\\]\n\n\\(S_{Q}\\)= 0 means that the curve is symmetrical.\n\\(S_{Q}\\) &gt; 0 means the curve is positively skewed.\n\\(S_{Q}\\)&lt; 0 means the curve is negatively skewed.\n\nLets find Bowley’s measure of skewness for Table 7.1 in Example 7.1 from the cumulative frequency in Table 7.3, quartiles can be calculated. Calculation of\\(\\text{Q}_{1}\\), \\(Q_{2}\\), \\(Q_{3}\\) is given in Section 5.6.\n\\[{Q}_{1} = 60\\]\n\\[Q_{2} = 61\\]\n\\[Q_{3} = 63\\]\n\\[S_{Q} = \\frac{63 - (2 \\times 61) + 60}{63 - 60} = \\ \\frac{1}{3} = 0.33\\]\nSince \\(S_{Q}\\) &gt; 0 means the curve is positively skewed.\n\n\n7.2.3 Kelly’s measure of skewness (Sp)\nBowley’s measure of skewness is based on the middle 50% of the observations; it leaves 25% of the observations on each extreme of the distribution. As an improvement over Bowley’s measure, Kelly has suggested a measure based on Percentiles, including P10 and P90 so that only 10% of the observations on each extreme are ignored.\n\\[{Kelly's\\ Measure\\ of\\ Skewness,\\ S}_{p} = \\frac{\\left( P_{90} - P_{50} \\right) - \\left( P_{50} - P_{10} \\right)}{\\left( P_{90} - P_{50} \\right) + \\left( P_{50} - P_{10} \\right)} \\tag{7.5}\\]\n\n\n\n\n\n\nTry yourself\nTry to find Kelly’s Measure of Skewness for Table 7.1\n\n\n\n\n\n7.2.4 Measure based on moments\nBefore going into measuring skewness using moments, one should know what a moment is:\nMoments\nThe rth moment about mean of a distribution, denoted by μr is given by\n\\[\\mu_{r} = \\frac{\\sum_{i = 1}^{N}{f_{i}\\left( x_{i} - \\overline{x} \\right)^{r}}}{N} \\tag{7.6}\\]\nWhere \\(f_{i}\\) is the frequency of ith observation or class mark\\(\\ x_{i}\\), \\(N = \\sum_{}^{}f_{i}\\), number of observations\nMoment about mean is also called as central moment\nIf r = 0, \\(\\mu_{0} = \\frac{\\sum_{i = 1}^{N}{f_{i}\\left( x_{i} - \\overline{x} \\right)^{0}}}{N}\\) = 1\nIf r = 1, \\(\\mu_{1} = \\frac{\\sum_{i = 1}^{N}{f_{i}\\left( x_{i} - \\overline{x} \\right)^{1}}}{N}\\) = 0 (sum of deviation about mean is zero)\nIf r = 2, \\(\\mu_{2} = \\frac{\\sum_{i = 1}^{N}{f_{i}\\left( x_{i} - \\overline{x} \\right)^{2}}}{N}\\) = \\(\\sigma^{2}\\), Population variance\nIn short values of following moments about mean are\n\n\n\nTable 7.4: Moments about mean\n\n\n\n\n\nMoments about mean\nValue\n\n\n\n\n\\[\\mu_{0}\\]\n1\n\n\n\\[\\mu_{1}\\]\n0\n\n\n\\[\\mu_{2}\\]\n\\(\\sigma^{2}\\)\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt should be remembered that first moment about mean is 0 and second moment about mean is variance.\n\n\nfor Table 7.1 in Example 7.1 given above, calculate third central moment, \\(\\mu_{3}\\)\n\n\n\nTable 7.5: Third central moment calculation\n\n\n\n\n\n\nHeight (\\(x_{i}\\))\n\n\nfrequency (\\(f_{i}\\))\n\n\n\\(\\left( x_{i}-\\overline{x} \\right)^{3}\\)\n\n\n\\({f_{i}\\left( x_{i}-\\overline{x}\\right)}^{3}\\)\n\n\n\n\n\n\n58\n\n\n10\n\n\n-39.304\n\n\n-393.040\n\n\n\n\n59\n\n\n18\n\n\n-13.824\n\n\n-248.832\n\n\n\n\n60\n\n\n30\n\n\n-2.744\n\n\n-82.320\n\n\n\n\n61\n\n\n42\n\n\n-0.064\n\n\n-2.688\n\n\n\n\n62\n\n\n35\n\n\n0.216\n\n\n7.560\n\n\n\n\n63\n\n\n28\n\n\n4.096\n\n\n114.688\n\n\n\n\n64\n\n\n16\n\n\n17.576\n\n\n281.216\n\n\n\n\n65\n\n\n8\n\n\n46.656\n\n\n373.248\n\n\n\n\nSum\n\n\n187\n\n\n12.608\n\n\n49.832\n\n\n\n\n\n\n\nMean = 61.40\n\\[\\mu_{3} = \\frac{\\sum_{i = 1}^{N}{f_{i}\\left( x_{i} - \\overline{x} \\right)^{3}}}{N} = \\ \\frac{49.832}{187} = 0.266\\]\n\nBeta one and gamma one\nThe moment measure of skewness is based on the property that, for a symmetrical distribution, all odd ordered central moments are equal to zero. We note that \\(\\mu_{1}\\) = 0, for every distribution, therefore, the lowest order moment that can provide an absolute measure of skewness is \\(\\text{μ}_{3}\\). So measures of skewness are based on \\(\\text{μ}_{3}\\).\n\\[\\beta_{1} = \\frac{\\mu_{3}^{2}}{\\mu_{2}^{3}} \\tag{7.7}\\]\nPronounced as ‘beta one’\n\\(\\beta_{1}\\)= 0 means that the curve is symmetrical. The greater the value of \\(\\beta_{1}\\) the more skewed the distribution. One serious limitation of \\(\\beta_{1}\\) is that it cannot tell the direction of skewness i.e. whether it is positive or negative. Since \\(\\text{μ}_{2}\\) is always positive (as it is variance) and \\(\\mu_{3}^{2}\\) is positive, \\(\\beta_{1}\\) will be positive always. This drawback is removed by calculating \\(\\text{γ}_{1}\\), called as Karl Pearson’s\\(\\text{ γ}_{1}\\), pronounced as ‘gamma one’.\n\\[\\gamma_{1} = \\sqrt{\\beta_{1}} = \\frac{\\mu_{3}}{\\mu_{2}^{3}} \\tag{7.8}\\]\nIf \\(\\mu_{3}\\) is positive \\(\\gamma_{1}\\) is positive, If \\(\\mu_{3}\\) is negative \\(\\gamma_{1}\\) is negative\n\n\\(\\gamma_{1}\\)= 0 means that the curve is symmetrical.\n\\(\\gamma_{1}\\) &gt; 0 means the curve is positively skewed.\n\\(\\gamma_{1}\\)&lt; 0 means the curve is negatively skewed.\n\nfor Table 7.1 in Example 7.1, \\(\\beta_{1}\\) and \\(\\gamma_{1}\\) can be calculated as follows\n\\(\\mu_{3}\\)= 0.226\n\\(\\mu_{2}\\)= 3.123\n\\(\\beta_{1} = \\frac{\\mu_{3}^{2}}{\\mu_{2}^{3}}\\) = \\(\\frac{\\left( 0.226 \\right)^{2}}{\\left( 3.123 \\right)^{3}} = \\ \\frac{0.051}{30.46} = 0.0016\\)\n\\(\\gamma_{1} = \\sqrt{\\beta_{1}} = \\ \\sqrt{0.0016} = + 0.04\\)\nSince \\(\\mu_{3}\\) is positive \\(\\gamma_{1}\\)is positive. Since \\(\\gamma_{1}\\) is slightly greater than 0, distribution is a slightly skewed to right.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Skewness and kurtosis</span>"
    ]
  },
  {
    "objectID": "skewness.html#kurtosis",
    "href": "skewness.html#kurtosis",
    "title": "7  Skewness and kurtosis",
    "section": "7.3 Kurtosis",
    "text": "7.3 Kurtosis\nKurtosis is a statistical measure that describes the shape of a distribution’s frequency curve, focusing on its relative peakedness. While skewness measures the asymmetry or lack of symmetry in a distribution, kurtosis evaluates how sharp or flat the peak of the curve is. There are three categories of frequency curves depending upon the shape of their peak as shown in Figure 7.8.\n\n\n\n\n\n\nFigure 7.8: Three categories of frequency curves\n\n\n\nKurtosis refers to degree of flatness or peakedness of the curve. It is measured relative to the peakedness of normal curve. The normal curve is considered as mesokurtic. If a curve is more peaked than normal curve, it is called leptokurtic. If a curve is more flat-topped than normal curve, it is called platykurtic. The condition of peakedness (leptokurtic) or flatness (platykurtic) is called kurtosis of excess.\n\n7.3.1 Measure of kurtosis\nKurtosis is measured using \\(\\beta_{2}\\) ‘beta two’ and \\(\\gamma_{2}\\) ‘gamma two’ given by Karl Pearson\n\\[\\beta_{2} = \\frac{\\mu_{4}}{\\mu_{2}^{2}} \\tag{7.9}\\]\nWhere \\(\\mu_{4}\\) is the 4th central moment, \\(\\mu_{2}\\) is the 2nd central moment\n\n\\(\\beta_{2}\\)= 3 means that the curve is mesokurtic.\n\\(\\beta_{2}\\) &gt; 3 means the curve is leptokurtic.\n\\(\\beta_{2}\\)&lt; 3 means the curve is platykurtic.\n\n\\[\\gamma_{2} = \\beta_{2} - 3 \\tag{7.10}\\]\n\n\\(\\gamma_{2}\\)= 0 means that the curve is mesokurtic.\n\\(\\gamma_{2}\\) &gt; 0 means the curve is leptokurtic.\n\\(\\gamma_{2}\\)&lt; 0 means the curve is platykurtic.\n\nfor Table 7.1 in Example 7.1, kurtosis can be examined as follows\n\n\n\nTable 7.6: Measures of kurtosis\n\n\n\n\n\n\nHeight (\\(x_{i}\\))\n\n\nfrequency (\\(f_{i}\\))\n\n\n\\(\\left( x_{i}-\\overline{x} \\right)^{4}\\)\n\n\n\\({f_{i}\\left( x_{i}-\\overline{x}\\right)}^{4}\\)\n\n\n\n\n\n\n58\n\n\n10\n\n\n133.634\n\n\n1336.336\n\n\n\n\n59\n\n\n18\n\n\n33.178\n\n\n597.197\n\n\n\n\n60\n\n\n30\n\n\n3.842\n\n\n115.248\n\n\n\n\n61\n\n\n42\n\n\n0.026\n\n\n1.075\n\n\n\n\n62\n\n\n35\n\n\n0.130\n\n\n4.536\n\n\n\n\n63\n\n\n28\n\n\n6.554\n\n\n183.501\n\n\n\n\n64\n\n\n16\n\n\n45.698\n\n\n731.162\n\n\n\n\n65\n\n\n8\n\n\n167.962\n\n\n1343.693\n\n\n\n\nSum\n\n\n187\n\n\n391.021\n\n\n4312.747\n\n\n\n\n\n\n\nMean, \\(\\overline{x}\\)= 61.40\n\\(\\mu_{2}\\) = 3.123 (calculation shown in previous example)\n\\(\\mu_{4} = \\frac{\\sum_{i = 1}^{N}{f_{i}\\left( x_{i} - \\overline{x} \\right)^{4}}}{N} = \\frac{4312.747}{187} = 23.062\\)\n\\(\\beta_{2} = \\frac{\\mu_{4}}{\\mu_{2}^{2}} = \\frac{23.062}{\\left( 3.123 \\right)^{2}} = 2.364\\)\n\\(\\beta_{2}\\) is 2.364, which is close to 3, distribution can be considered slightly platykurtic close to symmetric.\nYou can verify the frequency curve of Example 7.1 Figure 7.9, it can be seen that it is slightly right tailed (positively skewed)\n\n\n\n\n\n\nFigure 7.9: Frequency curve of Example 7.1\n\n\n\n \n \n \n\n\n\n\n\n\nHistorical Insights\n\n\n\n“Crabs and kurtosis”\nThe story of kurtosis and skewness begins with a fascinating scientific journey involving crabs! In the late 1800s, Karl Pearson, a pioneering statistician, worked with biologist Walter Weldon to study variations in the size of crustaceans, like crabs. They noticed that the data didn’t follow the usual normal pattern, so Pearson developed new tools to better understand the shapes of these unusual data distributions.\nHe created the concept of skewness to measure whether the data was symmetrical or had long tails on one side. Then, he developed kurtosis, a measure of how “peaked” or “flat” the data distribution was compared to the normal curve. These ideas helped statisticians better analyze data that didn’t fit the typical patterns, paving the way for modern statistical tools we still use today! (Fiori and Zenga 2009)\n\n\n\n\n\n\n\n\nQuotes to Inspire\n\n\n\n“We are just statistics, born to consume resources” – Horace\n\n\n\n\n\n\n\nFiori, Anna M., and Michele Zenga. 2009. “Karl Pearson and the Origin of Kurtosis.” International Statistical Review 77 (1): 40–50. https://doi.org/10.1111/j.1751-5823.2009.00076.x.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Skewness and kurtosis</span>"
    ]
  },
  {
    "objectID": "appendix1.html",
    "href": "appendix1.html",
    "title": "8  Appendix 1",
    "section": "",
    "text": "Source of data related to different sectors\n\n\n\nSl No\nData Particulars\nSource\nOrganisation\n\n\n\n\n1.\nEstimates of area, production of important crops in India\nhttps://agriwelfare.gov.in/en/AgricultureEstimates\nMoAFW, GOI\n\n\n2.\nState level, district level aggregates of Area, production and productivity of principal crops in Kerala\nhttps://www.ecostat.kerala.gov.in\nDepartment of Economics & Statistics, Govt of Kerala\n\n\n3.\nDistrict Wise Birth & Death Data, State Level Birth & Death Data\nhttps://www.ecostat.kerala.gov.in\nDepartment of Economics & Statistics, Govt of Kerala\n\n\n4.\nMinimum Support Price (MSP) Statement\nhttps://desagri.gov.in/statistics-type/latest-minimum-support-price-msp-statement/\nMoAFW, GOI\n\n\n5.\nAnnual Survey of Industries, Index of Industrial Production, Household Consumer Expenditure, Economic Census, Enterprises Surveys, Periodic Labour Force Survey, CPI, etc\nhttps://www.mospi.gov.in/\nMinistry of Statistics and Programme Implementation\n\n\n6.\nState/UT wise estimates on population, health, family planning and nutrition related key indicators like fertility, mortality, maternal, child and adult health, women and child nutrition, domestic violence, etc\nhttps://main.mohfw.gov.in/\nMinistry of Health & Family Welfare\n\n\n7.\nCommodity wise export import data\nhttps://tradestat.commerce.gov.in, https://ftddp.dgciskol.gov.in\nMinistry of Commerce and Industry\n\n\n8.\nData on various aspects of Indian economy, banking and finance\nhttps://www.rbi.org.in\nReserve Bank of India\n\n\n9.\nSustainable Development Goal report\nhttps://www.niti.gov.in/\nNITI Aayog",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix 1</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "9  References",
    "section": "",
    "text": "Ball, Philip. 2004. Critical Mass. Farrar, Straus; Giroux.\n\n\nFisher, Ronald A. 1918. “The Correlation Between Relatives on the\nSupposition of Mendelian Inheritance.” Transactions of the\nRoyal Society of Edinburgh 52 (2): 399–433. https://doi.org/10.1017/S0080456800012163.\n\n\nGoon, Gupta, A. M., and B Dasgupta. 1983. Fundamentals of\nStatistics. Vol. I. TheWorld Press.\n\n\nGupta, S. C., and V. K. Kapoor. 1997. Fundamentals of Mathematical\nStatistics. Sulthan Chand Publications, New Delhi.\n\n\nPearson, Karl. 1894. “Contributions to the Mathematical Theory of\nEvolution.” Philosophical Transactions of the Royal Society\nof London. A 185: 71–110. https://doi.org/10.1098/rsta.1894.0003.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>References</span>"
    ]
  }
]